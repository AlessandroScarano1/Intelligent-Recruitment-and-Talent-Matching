{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded\n",
      "Project root: /home/developer/project\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# lets recruiters paste/upload a job posting and find the top matching CVs.\n",
    "\n",
    "# 1. Paste job posting text or upload PDF/DOCX/TXT file\n",
    "# 2. Extract skills using NLP (PhraseMatcher with skill dictionary)\n",
    "# 3. Build embedding string from extracted fields\n",
    "# 4. Encode job with bi-encoder and search CV index\n",
    "# 5. Rerank top candidates with cross-encoder\n",
    "# 6. Display results with action buttons for feedback\n",
    "\n",
    "# Input:\n",
    "# - Job posting text (pasted or uploaded)\n",
    "# - CV index: `training/output/indexes/cvs_index.faiss` (7,299 CVs)\n",
    "# - CV data: `ingest_cv/output/cv_query_text.parquet`\n",
    "# - Skill dictionary: `training/output/skill_dictionary/all_skills`\n",
    "# - Bi-encoder model: `training/output/models/cv-job-matcher-e5`\n",
    "\n",
    "#Output:\n",
    "# - Top 10 matching CVs ranked by cross-encoder score\n",
    "# - Recruiter feedback logged to `demo/data/feedback/feedback.db`\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ipython display\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# add project root to path\n",
    "cwd = os.getcwd()\n",
    "if 'notebooks' in cwd:\n",
    "    PROJECT_ROOT = os.path.dirname(os.path.dirname(cwd))  # TWO levels up\n",
    "else:\n",
    "    PROJECT_ROOT = cwd\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# models\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "\n",
    "# our modules\n",
    "from demo.scripts.feedback_storage import init_db, log_action, get_action_count\n",
    "from demo.scripts.document_parser import parse_document\n",
    "\n",
    "print(\"Imports loaded\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: cv-job-matcher-e5\n",
      "OK: cvs_index.faiss\n",
      "OK: cv_query_text.parquet\n",
      "OK: all_skills\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "MODEL_PATH = os.path.join(PROJECT_ROOT, 'training', 'output', 'models', 'cv-job-matcher-e5')\n",
    "CV_INDEX_PATH = os.path.join(PROJECT_ROOT, 'training', 'output', 'indexes', 'cvs_index.faiss')\n",
    "CV_DATA_PATH = os.path.join(PROJECT_ROOT, 'ingest_cv', 'output', 'cv_query_text.parquet')\n",
    "SKILL_DICT_PATH = os.path.join(PROJECT_ROOT, 'training', 'output', 'skill_dictionary', 'all_skills')\n",
    "\n",
    "# check files exist\n",
    "for path in [MODEL_PATH, CV_INDEX_PATH, CV_DATA_PATH, SKILL_DICT_PATH]:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"OK: {os.path.basename(path)}\")\n",
    "    else:\n",
    "        print(f\"MISSING: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 18:05:43,562 - Load pretrained SentenceTransformer: /home/developer/project/training/output/models/cv-job-matcher-e5\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bi-encoder: 768D embeddings\n"
     ]
    }
   ],
   "source": [
    "# load bi-encoder model\n",
    "# load with fp16 for faster inference\n",
    "bi_encoder = SentenceTransformer(\n",
    "    MODEL_PATH,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}  # fp16 precision\n",
    ")\n",
    "embedding_dim = bi_encoder.get_sentence_embedding_dimension()\n",
    "print(f\"Loaded bi-encoder: {embedding_dim}D embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cross-encoder on cuda\n"
     ]
    }
   ],
   "source": [
    "# load cross-encoder for reranking\n",
    "# cross-encoder handles asymmetric direction: model trained CV->Job but we need Job->CV\n",
    "# MS MARCO model works both directions for reranking\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L12-v2\", device=device)\n",
    "print(f\"Loaded cross-encoder on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CV index: 7,299 CVs\n"
     ]
    }
   ],
   "source": [
    "# load CV faiss index\n",
    "cvs_index = faiss.read_index(CV_INDEX_PATH)\n",
    "# set nprobe for IVF index if applicable\n",
    "if hasattr(cvs_index, 'nprobe'):\n",
    "    cvs_index.nprobe = 20\n",
    "print(f\"Loaded CV index: {cvs_index.ntotal:,} CVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7,299 CVs\n",
      "Columns: ['id', 'text']\n",
      "Sample ID: A1\n"
     ]
    }
   ],
   "source": [
    "# load CV data\n",
    "cvs_df = pd.read_parquet(CV_DATA_PATH)\n",
    "print(f\"Loaded {len(cvs_df):,} CVs\")\n",
    "print(f\"Columns: {cvs_df.columns.tolist()}\")\n",
    "print(f\"Sample ID: {cvs_df['id'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,770,595 skills\n",
      "Sample: ['vorne data analysis', 'victim and witness interviews', 'ability to recognize each person as a unique individual', 'ability to follow directions and take initiative', 'manoverboard rescues', 'flexibile working hours', 'telephonic setting', 'counting accuracy', 'tolerance for change/ambiguity', 'operational policing']\n"
     ]
    }
   ],
   "source": [
    "# load skill dictionary\n",
    "skills_df = pd.read_parquet(SKILL_DICT_PATH)\n",
    "# skill column is the first column\n",
    "skill_col = skills_df.columns[0]\n",
    "skill_set = set(skills_df[skill_col].str.lower().str.strip().tolist())\n",
    "print(f\"Loaded {len(skill_set):,} skills\")\n",
    "# show some examples\n",
    "sample_skills = list(skill_set)[:10]\n",
    "print(f\"Sample: {sample_skills}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseMatcher ready with 2,770,595 skills in 278 batches\n"
     ]
    }
   ],
   "source": [
    "# setup spacy PhraseMatcher for skill extraction\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "\n",
    "# add skills in batches to avoid memory issues\n",
    "skill_list = list(skill_set)\n",
    "batch_size = 10000\n",
    "for i in range(0, len(skill_list), batch_size):\n",
    "    batch = skill_list[i:i+batch_size]\n",
    "    patterns = [nlp.make_doc(skill) for skill in batch]\n",
    "    matcher.add(f\"SKILLS_{i}\", patterns)\n",
    "\n",
    "print(f\"PhraseMatcher ready with {len(skill_list):,} skills in {len(skill_list)//batch_size + 1} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized at /home/developer/project/demo/data/feedback/feedback.db\n",
      "Feedback database initialized\n",
      "Current action count: 38\n",
      "Results to show: 10\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION: Number of results to show\n",
    "# Change this value to see more or fewer results\n",
    "NUM_RESULTS = 10\n",
    "\n",
    "# initialize feedback database\n",
    "init_db()\n",
    "print(f\"Feedback database initialized\")\n",
    "print(f\"Current action count: {get_action_count()}\")\n",
    "print(f\"Results to show: {NUM_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test extraction: ['senior', 'python', 'developer', 'with', 'django', 'and', 'aws', 'aws experience', 'experience', 'postgresql', 'required']\n"
     ]
    }
   ],
   "source": [
    "# nlp\n",
    "# these functions extract structured information from raw job posting text\n",
    "\n",
    "# skill extraction function\n",
    "def extract_skills_from_job(job_text):\n",
    "    \"\"\"\n",
    "    Extract skills from job posting using PhraseMatcher.\n",
    "    \n",
    "    Uses the skill dictionary loaded from output/skill_dictionary/all_skills\n",
    "    and spacy PhraseMatcher for fast matching.\n",
    "    \"\"\"\n",
    "    if not job_text or not str(job_text).strip():\n",
    "        return []\n",
    "    \n",
    "    # create doc from lowercased text\n",
    "    doc = nlp(job_text.lower())\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # extract matched skills\n",
    "    skills = []\n",
    "    for match_id, start, end in matches:\n",
    "        skill = doc[start:end].text\n",
    "        # skip single character matches\n",
    "        if len(skill) > 1:\n",
    "            skills.append(skill)\n",
    "    \n",
    "    # remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_skills = []\n",
    "    for s in skills:\n",
    "        s_lower = s.lower()\n",
    "        if s_lower not in seen:\n",
    "            seen.add(s_lower)\n",
    "            unique_skills.append(s)\n",
    "    \n",
    "    return unique_skills\n",
    "\n",
    "# test it\n",
    "test_text = \"Senior Python Developer with Django and AWS experience. PostgreSQL required.\"\n",
    "extracted = extract_skills_from_job(test_text)\n",
    "print(f\"Test extraction: {extracted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Senior Python Developer\n",
      "Company: TechCorp Inc.\n",
      "Location: San Francisco, CA (Remote OK)\n",
      "Skills: ['senior', 'python', 'developer', 'company', 'inc']\n",
      "Salary: $150,000 - $180,000\n",
      "Experience: 5+\n",
      "Remote: remote\n",
      "Seniority: senior\n"
     ]
    }
   ],
   "source": [
    "# extract structured job fields\n",
    "def extract_job_fields(job_text):\n",
    "    \"\"\"\n",
    "    Extract structured fields from job posting text.\n",
    "    \n",
    "    Extracts: title, company, location, skills, experience, salary, remote status\n",
    "    \"\"\"\n",
    "    fields = {\n",
    "        'title': '',\n",
    "        'company': '',\n",
    "        'location': '',\n",
    "        'skills': [],\n",
    "        'experience_years': '',\n",
    "        'salary_min': None,\n",
    "        'salary_max': None,\n",
    "        'remote_status': '',\n",
    "        'seniority': 'mid'  # default\n",
    "    }\n",
    "    \n",
    "    if not job_text:\n",
    "        return fields\n",
    "    \n",
    "    # extract skills using PhraseMatcher\n",
    "    fields['skills'] = extract_skills_from_job(job_text)\n",
    "    \n",
    "    # extract title - usually first non-empty line\n",
    "    lines = job_text.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.lower().startswith(('company', 'location', 'salary', 'type')):\n",
    "            fields['title'] = line[:100]\n",
    "            break\n",
    "    \n",
    "    # extract company\n",
    "    company_match = re.search(r'company[:\\s]+([^\\n]+)', job_text, re.I)\n",
    "    if company_match:\n",
    "        fields['company'] = company_match.group(1).strip()[:100]\n",
    "    \n",
    "    # extract location\n",
    "    location_match = re.search(r'location[:\\s]+([^\\n]+)', job_text, re.I)\n",
    "    if location_match:\n",
    "        fields['location'] = location_match.group(1).strip()[:100]\n",
    "    \n",
    "    # extract salary range\n",
    "    salary_match = re.search(r'\\$?([\\d,]+)\\s*[-\\u2013]\\s*\\$?([\\d,]+)', job_text)\n",
    "    if salary_match:\n",
    "        try:\n",
    "            fields['salary_min'] = int(salary_match.group(1).replace(',', ''))\n",
    "            fields['salary_max'] = int(salary_match.group(2).replace(',', ''))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # extract experience years\n",
    "    exp_match = re.search(r'(\\d+)\\+?\\s*years?', job_text, re.I)\n",
    "    if exp_match:\n",
    "        fields['experience_years'] = exp_match.group(1) + '+'\n",
    "    \n",
    "    # detect remote status\n",
    "    if re.search(r'\\bremote\\b', job_text, re.I):\n",
    "        fields['remote_status'] = 'remote'\n",
    "    elif re.search(r'\\bhybrid\\b', job_text, re.I):\n",
    "        fields['remote_status'] = 'hybrid'\n",
    "    else:\n",
    "        fields['remote_status'] = 'onsite'\n",
    "    \n",
    "    # detect seniority from title\n",
    "    title_lower = fields['title'].lower()\n",
    "    if any(w in title_lower for w in ['intern', 'internship', 'trainee']):\n",
    "        fields['seniority'] = 'intern'\n",
    "    elif any(w in title_lower for w in ['principal', 'staff', 'distinguished']):\n",
    "        fields['seniority'] = 'principal'\n",
    "    elif any(w in title_lower for w in ['lead', 'head of', 'director', 'vp', 'chief']):\n",
    "        fields['seniority'] = 'lead'\n",
    "    elif any(w in title_lower for w in ['senior', 'sr.', 'sr ']):\n",
    "        fields['seniority'] = 'senior'\n",
    "    elif any(w in title_lower for w in ['junior', 'jr.', 'jr ', 'entry']):\n",
    "        fields['seniority'] = 'junior'\n",
    "    else:\n",
    "        fields['seniority'] = 'mid'\n",
    "    \n",
    "    return fields\n",
    "\n",
    "# test it\n",
    "test_job = \"\"\"Senior Python Developer\n",
    "\n",
    "Company: TechCorp Inc.\n",
    "Location: San Francisco, CA (Remote OK)\n",
    "Salary: $150,000 - $180,000\n",
    "\n",
    "Requirements:\n",
    "- 5+ years of Python development\n",
    "- Django or FastAPI experience\n",
    "\"\"\"\n",
    "fields = extract_job_fields(test_job)\n",
    "print(f\"Title: {fields['title']}\")\n",
    "print(f\"Company: {fields['company']}\")\n",
    "print(f\"Location: {fields['location']}\")\n",
    "print(f\"Skills: {fields['skills'][:5]}\")\n",
    "print(f\"Salary: ${fields['salary_min']:,} - ${fields['salary_max']:,}\")\n",
    "print(f\"Experience: {fields['experience_years']}\")\n",
    "print(f\"Remote: {fields['remote_status']}\")\n",
    "print(f\"Seniority: {fields['seniority']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding string (319 chars):\n",
      "passage: Role of Senior Python Developer at TechCorp Inc. in San Francisco, CA (Remote OK). Required skills: senior, python, developer, company, inc, inc., location, location:, san, san francisco. Experience level: Senior level, 5+ years experience. Salary range: $150,000 to $180,000. Work type: Remote work available.\n"
     ]
    }
   ],
   "source": [
    "# cell 12: build embedding string from extracted fields\n",
    "# follows pattern from notebook 04_embedding_strings.ipynb\n",
    "def build_job_embedding_string(fields):\n",
    "\n",
    "    # Build natural language embedding string from extracted job fields.\n",
    "    \n",
    "    # Template\n",
    "    # \"Role of {title} at {company} in {location}. Required skills: {skills}.\n",
    "    #  Experience level: {seniority}. Salary: {salary}. Work type: {remote}.\"\"\n",
    "\n",
    "    parts = []\n",
    "    \n",
    "    # role and company\n",
    "    title = fields.get('title', 'Unknown Position')\n",
    "    company = fields.get('company', 'a company')\n",
    "    location = fields.get('location', '')\n",
    "    \n",
    "    role_part = f\"Role of {title} at {company}\"\n",
    "    if location:\n",
    "        role_part += f\" in {location}\"\n",
    "    parts.append(role_part + \".\")\n",
    "    \n",
    "    # skills - limit to top 10\n",
    "    skills = fields.get('skills', [])\n",
    "    if skills:\n",
    "        skills_str = ', '.join(skills[:10])\n",
    "        parts.append(f\"Required skills: {skills_str}.\")\n",
    "    \n",
    "    # seniority with expanded descriptions\n",
    "    seniority = fields.get('seniority', 'mid')\n",
    "    seniority_map = {\n",
    "        'intern': 'Intern level, entry position',\n",
    "        'junior': 'Junior level, 0-2 years experience',\n",
    "        'mid': 'Mid-level, 3-5 years experience',\n",
    "        'senior': 'Senior level, 5+ years experience',\n",
    "        'lead': 'Lead level, 7+ years experience with leadership',\n",
    "        'principal': 'Principal level, expert with technical leadership'\n",
    "    }\n",
    "    level_desc = seniority_map.get(seniority, seniority)\n",
    "    parts.append(f\"Experience level: {level_desc}.\")\n",
    "    \n",
    "    # salary if available\n",
    "    salary_min = fields.get('salary_min')\n",
    "    salary_max = fields.get('salary_max')\n",
    "    if salary_min and salary_max:\n",
    "        parts.append(f\"Salary range: ${salary_min:,} to ${salary_max:,}.\")\n",
    "    elif salary_min:\n",
    "        parts.append(f\"Minimum salary: ${salary_min:,}.\")\n",
    "    \n",
    "    # remote status\n",
    "    remote = fields.get('remote_status', '')\n",
    "    if remote:\n",
    "        remote_map = {\n",
    "            'remote': 'Remote work available',\n",
    "            'hybrid': 'Hybrid work, partially remote',\n",
    "            'onsite': 'Onsite work'\n",
    "        }\n",
    "        work_type = remote_map.get(remote, remote)\n",
    "        parts.append(f\"Work type: {work_type}.\")\n",
    "    \n",
    "    text = ' '.join(parts)\n",
    "    \n",
    "    # add passage prefix for e5 model\n",
    "    return \"passage: \" + text\n",
    "\n",
    "# test it\n",
    "embedding_str = build_job_embedding_string(fields)\n",
    "print(f\"Embedding string ({len(embedding_str)} chars):\")\n",
    "print(embedding_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_matching_cvs() defined\n"
     ]
    }
   ],
   "source": [
    "# These functions find and rank matching CVs for a given job posting\n",
    "\n",
    "# find matching CVs using bi-encoder and faiss\n",
    "def find_matching_cvs(job_text, top_k=50):\n",
    "    # find top-k matching CVs for a job posting\n",
    "    \n",
    "    # Steps:\n",
    "    # 1. Extract fields from job text\n",
    "    # 2. Build embedding string\n",
    "    # 3. Encode with bi-encoder\n",
    "    # 4. Search CV index with faiss\n",
    "    # Returns:\n",
    "    #     matches: list of dicts with cv_id, bi_score, text\n",
    "    #     fields: extracted job fields\n",
    "\n",
    "    # extract fields\n",
    "    fields = extract_job_fields(job_text)\n",
    "    print(f\"  Extracted {len(fields['skills'])} skills: {fields['skills'][:5]}\")\n",
    "    \n",
    "    # build embedding string\n",
    "    embedding_text = build_job_embedding_string(fields)\n",
    "    print(f\"  Embedding string: {embedding_text[:80]}\")\n",
    "    # encode with bi-encoder\n",
    "    job_embedding = bi_encoder.encode(\n",
    "        [embedding_text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    # search CV index\n",
    "    distances, indices = cvs_index.search(job_embedding, top_k)\n",
    "    \n",
    "    # build results\n",
    "    matches = []\n",
    "    for rank, (dist, idx) in enumerate(zip(distances[0], indices[0]), 1):\n",
    "        if idx >= 0 and idx < len(cvs_df):\n",
    "            cv_row = cvs_df.iloc[idx]\n",
    "            matches.append({\n",
    "                'rank': rank,\n",
    "                'cv_id': cv_row['id'],\n",
    "                'bi_score': float(dist),\n",
    "                'text': cv_row['text'],\n",
    "                'idx': int(idx)\n",
    "            })\n",
    "    \n",
    "    return matches, fields\n",
    "\n",
    "print(\"find_matching_cvs() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rerank_cvs() defined\n"
     ]
    }
   ],
   "source": [
    "# rerank CVs with cross-encoder\n",
    "def rerank_cvs(job_text, matches, top_k=10):\n",
    "    # rerank CV matches using cross-encoder\n",
    "    \n",
    "    # Cross-encoder handles asymmetric direction:\n",
    "    # - Our bi-encoder was trained CV->Job\n",
    "    # - MS MARCO cross-encoder works both directions for reranking\n",
    "    \n",
    "    # Args:\n",
    "    #     job_text: raw job posting text\n",
    "    #     matches: list of match dicts from find_matching_cvs\n",
    "    #     top_k: number of results to return\n",
    "    \n",
    "    # Returns:\n",
    "    #     reranked list of matches with cross_score added\n",
    "    if not matches:\n",
    "        return []\n",
    "    \n",
    "    # clean job text - remove any prefixes\n",
    "    clean_job = job_text.replace(\"passage: \", \"\").replace(\"query: \", \"\")\n",
    "    \n",
    "    # create pairs for cross-encoder: (job, cv)\n",
    "    pairs = []\n",
    "    for m in matches:\n",
    "        clean_cv = m['text'].replace(\"query: \", \"\").replace(\"Query: \", \"\")\n",
    "        pairs.append((clean_job, clean_cv))\n",
    "    \n",
    "    # score with cross-encoder\n",
    "    print(f\"  Reranking {len(pairs)} candidates with cross-encoder\")\n",
    "    cross_scores = cross_encoder.predict(pairs, batch_size=50)\n",
    "    \n",
    "    # add scores to matches\n",
    "    for m, score in zip(matches, cross_scores):\n",
    "        m['cross_score'] = float(score)\n",
    "    \n",
    "    # sort by cross-encoder score descending\n",
    "    reranked = sorted(matches, key=lambda x: x['cross_score'], reverse=True)\n",
    "    \n",
    "    return reranked[:top_k]\n",
    "\n",
    "print(\"rerank_cvs() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: 0d46cf80\n"
     ]
    }
   ],
   "source": [
    "# session state\n",
    "session_id = str(uuid.uuid4())[:8]\n",
    "current_job_text = None\n",
    "current_job_id = None\n",
    "current_matches = []\n",
    "current_job_skills = []\n",
    "current_run_id = 0  # tracks which search run buttons belong to\n",
    "logged_actions = set()  # prevents duplicate action logging\n",
    "\n",
    "print(f\"Session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_cv_match() defined\n"
     ]
    }
   ],
   "source": [
    "# display single CV match\n",
    "def display_cv_match(match, idx, job_skills, run_id):\n",
    "    # Display a single CV match with score and action buttons.\n",
    "    # run_id is used to prevent stale button clicks\n",
    "\n",
    "    # find matching skills between job and cv\n",
    "    cv_text_lower = match['text'].lower()\n",
    "    matching_skills = [s for s in job_skills if s.lower() in cv_text_lower]\n",
    "\n",
    "    # determine score color\n",
    "    cross_score = match['cross_score']\n",
    "    if cross_score > 5:\n",
    "        score_color = '#90EE90'  # green\n",
    "    elif cross_score > 0:\n",
    "        score_color = '#FFD700'  # gold\n",
    "    else:\n",
    "        score_color = '#FFB6C1'  # pink\n",
    "\n",
    "    html = f'''\n",
    "    <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>CV #{idx+1}: {match['cv_id']}</h3>\n",
    "        <p><strong>Cross-Encoder Score:</strong> \n",
    "           <span style=\"background-color: {score_color}; padding: 2px 8px; border-radius: 3px;\">\n",
    "               {match['cross_score']:.2f}\n",
    "           </span>\n",
    "           (bi-encoder: {match['bi_score']:.4f})\n",
    "        </p>\n",
    "    '''\n",
    "\n",
    "    if matching_skills:\n",
    "        skills_str = ', '.join(matching_skills[:8])\n",
    "        html += f'<p><strong>Matching Skills:</strong> <span style=\"color: green;\">{skills_str}</span></p>'\n",
    "\n",
    "    # cv preview\n",
    "    preview = match['text'][:300].replace(\"query: \", \"\").replace(\"Query: \", \"\")\n",
    "    html += f'<p style=\"color: #666; font-style: italic;\">{preview}</p>'\n",
    "    html += '</div>'\n",
    "    display(HTML(html))\n",
    "\n",
    "    # action buttons\n",
    "    actions = [\n",
    "        ('View Full CV', 'view_full', 'info'),\n",
    "        ('Contact', 'contact', 'success'),\n",
    "        ('Shortlist', 'save', ''),\n",
    "        ('Skip', 'skip', 'warning'),\n",
    "        ('Not a Match', 'not_interested', 'danger')\n",
    "    ]\n",
    "\n",
    "    buttons = []\n",
    "    for label, action, style in actions:\n",
    "        btn = widgets.Button(\n",
    "            description=label,\n",
    "            button_style=style,\n",
    "            layout=widgets.Layout(width='110px')\n",
    "        )\n",
    "\n",
    "        # closure to capture match, action, and run_id\n",
    "        def make_callback(m=match, a=action, rid=run_id):\n",
    "            def cb(b):\n",
    "                # only process if this run is still current\n",
    "                if rid != current_run_id:\n",
    "                    return  # stale button, ignore\n",
    "                handle_recruiter_action(m, a, b)\n",
    "            return cb\n",
    "\n",
    "        btn.on_click(make_callback())\n",
    "        buttons.append(btn)\n",
    "\n",
    "    display(widgets.HBox(buttons))\n",
    "\n",
    "print(\"display_cv_match() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle_recruiter_action() defined\n",
      "display_cv_results() defined\n"
     ]
    }
   ],
   "source": [
    "# handle recruiter action\n",
    "def handle_recruiter_action(match, action, button=None):\n",
    "    # Handle recruiter action on a CV match.\n",
    "    # logs action to feedback database for future model improvement\n",
    "    global current_job_text, logged_actions\n",
    "\n",
    "    # create unique key for this action\n",
    "    action_key = f\"{current_run_id}_{match['cv_id']}_{action}\"\n",
    "\n",
    "    # skip if already logged (prevents duplicate clicks)\n",
    "    if action_key in logged_actions:\n",
    "        return\n",
    "    logged_actions.add(action_key)\n",
    "\n",
    "    # disable button to prevent double-click\n",
    "    if button:\n",
    "        button.disabled = True\n",
    "\n",
    "    # log to database\n",
    "    log_action(\n",
    "        session_id=session_id,\n",
    "        role='recruiter',\n",
    "        doc_id=current_job_id,\n",
    "        match_id=match['cv_id'],\n",
    "        action=action,\n",
    "        similarity=match['cross_score'],\n",
    "        cv_text=match['text'][:2000],\n",
    "        job_text=current_job_text[:2000] if current_job_text else ''\n",
    "    )\n",
    "\n",
    "    # feedback messages\n",
    "    action_msg = {\n",
    "        'contact': 'Marked for contact!',\n",
    "        'save': 'Added to shortlist.',\n",
    "        'skip': 'Skipped.',\n",
    "        'not_interested': 'Noted as not a match.',\n",
    "        'view_full': 'Showing full CV'\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{action_msg.get(action, 'Action recorded.')}\")\n",
    "    print(f\"Total actions logged: {get_action_count()}\")\n",
    "\n",
    "    # show full CV if requested\n",
    "    if action == 'view_full':\n",
    "        full_text = match['text'].replace(\"query: \", \"\").replace(\"Query: \", \"\")\n",
    "        print(f\"\\nFULL CV: {match['cv_id']}\")\n",
    "        print(f\"Bi-Score: {match['bi_score']:.4f}\")\n",
    "        print(f\"Cross-Score: {match['cross_score']:.2f}\")\n",
    "        print(f\"\\nCV Text:\")\n",
    "        print(full_text)\n",
    "\n",
    "\n",
    "def display_cv_results(matches, job_skills, show_top=10):\n",
    "    # Display CV matches\n",
    "    global current_run_id\n",
    "\n",
    "    page_matches = matches[:show_top]\n",
    "    run_id = current_run_id  # capture current run_id\n",
    "\n",
    "    print(f\"TOP {len(page_matches)} MATCHING CVs\")\n",
    "    print(f\"Showing {len(page_matches)} of {len(matches)}\")\n",
    "    print(\"Click View Full CV to see complete CV.\\n\")\n",
    "\n",
    "    for i, match in enumerate(page_matches):\n",
    "        display_cv_match(match, i, job_skills, run_id)\n",
    "\n",
    "\n",
    "print(\"handle_recruiter_action() defined\")\n",
    "print(\"display_cv_results() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widgets created\n"
     ]
    }
   ],
   "source": [
    "## Main Interface\n",
    "\n",
    "#Interactive widgets for job posting input and CV matchig\n",
    "# create interface widgets\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# job posting text input\n",
    "job_input = widgets.Textarea(\n",
    "    placeholder='Paste job posting here...\\n\\nOr upload a file below.',\n",
    "    layout=widgets.Layout(width='100%', height='200px')\n",
    ")\n",
    "\n",
    "# file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='.pdf,.docx,.doc,.txt',\n",
    "    multiple=False,\n",
    "    description='Upload Job'\n",
    ")\n",
    "\n",
    "# match button\n",
    "match_button = widgets.Button(\n",
    "    description='Find Matching CVs!',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "print(\"Widgets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click handler attached\n"
     ]
    }
   ],
   "source": [
    "# match button click handler\n",
    "# ROBUST DEBOUNCING using globals() for reliable persistence\n",
    "if '_nb13_last_search' not in globals():\n",
    "    globals()['_nb13_last_search'] = 0\n",
    "\n",
    "def on_match_click(b):\n",
    "    # Handle match button click.\n",
    "    global current_job_text, current_job_id, current_matches, current_job_skills\n",
    "    global current_run_id, logged_actions\n",
    "\n",
    "    # DEBOUNCE: Prevent duplicate calls within 1 second\n",
    "    import time\n",
    "    now = time.time()\n",
    "    if now - globals().get('_nb13_last_search', 0) < 1.0:\n",
    "        return\n",
    "    globals()['_nb13_last_search'] = now\n",
    "    \n",
    "    b.disabled = True\n",
    "\n",
    "    try:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # new search, increment run_id and clear logged actions\n",
    "            current_run_id += 1\n",
    "            logged_actions = set()\n",
    "\n",
    "            # get job text from input or file upload\n",
    "            if job_input.value.strip():\n",
    "                current_job_text = job_input.value.strip()\n",
    "                current_job_id = f\"input_{uuid.uuid4().hex[:8]}\"\n",
    "                print(f\"Using pasted text ({len(current_job_text)} chars)\")\n",
    "\n",
    "            elif file_upload.value:\n",
    "                print(\"Processing uploaded file\")\n",
    "                try:\n",
    "                    uploaded_data = file_upload.value\n",
    "\n",
    "                    if isinstance(uploaded_data, tuple) and len(uploaded_data) > 0:\n",
    "                        uploaded = uploaded_data[0]\n",
    "                        filename = uploaded.get('name', 'unknown')\n",
    "                        content = uploaded.get('content', b'')\n",
    "                    elif isinstance(uploaded_data, dict) and len(uploaded_data) > 0:\n",
    "                        first_key = list(uploaded_data.keys())[0]\n",
    "                        uploaded = uploaded_data[first_key]\n",
    "                        filename = uploaded.get('metadata', {}).get('name', first_key)\n",
    "                        content = uploaded.get('content', b'')\n",
    "                    else:\n",
    "                        print(f\"ERROR: Unexpected upload format: {type(uploaded_data)}\")\n",
    "                        return\n",
    "\n",
    "                    print(f\"File: {filename} ({len(content)} bytes)\")\n",
    "\n",
    "                    temp_path = Path(f\"/tmp/{filename}\")\n",
    "                    temp_path.write_bytes(content)\n",
    "\n",
    "                    print(f\"Parsing {filename}\")\n",
    "                    parsed = parse_document(temp_path)\n",
    "\n",
    "                    if parsed and parsed.get('text'):\n",
    "                        current_job_text = parsed['text']\n",
    "                        current_job_id = f\"file_{uuid.uuid4().hex[:8]}\"\n",
    "                        print(f\"Parsed: {parsed['word_count']} words\")\n",
    "                    else:\n",
    "                        print(\"ERROR: Could not parse uploaded file\")\n",
    "                        return\n",
    "\n",
    "                    temp_path.unlink(missing_ok=True)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR processing file: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    return\n",
    "            else:\n",
    "                print(\"Please enter a job posting or upload a file!\")\n",
    "                return\n",
    "\n",
    "            print(f\"\\nJob posting: {len(current_job_text)} characters\")\n",
    "            print(\"Finding matching CVs\")\n",
    "            print()\n",
    "\n",
    "            # find matches with bi-encoder\n",
    "            current_matches, fields = find_matching_cvs(current_job_text, top_k=50)\n",
    "            current_job_skills = fields['skills']\n",
    "\n",
    "            print(f\"Found {len(current_matches)} candidates from bi-encoder\")\n",
    "            print()\n",
    "\n",
    "            # rerank with cross-encoder\n",
    "            current_matches = rerank_cvs(current_job_text, current_matches, top_k=NUM_RESULTS)\n",
    "\n",
    "            # display results\n",
    "            print(f\"\\nJob: {fields['title'][:50]}\")\n",
    "            print(f\"Skills: {', '.join(fields['skills'][:5])}\\n\")\n",
    "\n",
    "            display_cv_results(current_matches, current_job_skills, show_top=NUM_RESULTS)\n",
    "\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "# ALWAYS register handler - button is created fresh each cell run\n",
    "match_button.on_click(on_match_click)\n",
    "\n",
    "print(\"Click handler attached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECRUITER MODE: Find Matching CVs\n",
      "Searching 7,299 CVs with trained bi-encoder model\n",
      "Paste job posting text OR upload a PDF/DOCX/TXT file\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abda5632d6b54bb5894896d4aff78740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Enter job posting:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0c69edde494627b4dc4e1ef9470559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='200px', width='100%'), placeholder='Paste job posting here...\\n\\nOr u…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5917c7486f749b8a1d33467586e9510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf,.docx,.doc,.txt', description='Upload Job')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbdc5f53e5f4619b47d3e8631bb717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Find Matching CVs!', layout=Layout(width='200px'), style=ButtonSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591f3f490d1146e0be365fc703d29b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display interface\n",
    "print(\"RECRUITER MODE: Find Matching CVs\")\n",
    "print(f\"Searching {cvs_index.ntotal:,} CVs with trained bi-encoder model\")\n",
    "print(\"Paste job posting text OR upload a PDF/DOCX/TXT file\")\n",
    "print()\n",
    "\n",
    "display(widgets.Label(\"Enter job posting:\"))\n",
    "display(job_input)\n",
    "display(file_upload)\n",
    "display(match_button)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECRUITER MODE DEMO INSTRUCTIONS\n",
      "\n",
      "1. ENTER JOB POSTING:\n",
      "   - Paste job description text directly into the text area, OR\n",
      "   - Click \"Upload\" to select a PDF, DOCX, or TXT file\n",
      "\n",
      "2. CLICK \"Find Matching CVs!\" BUTTON\n",
      "\n",
      "3. REVIEW RESULTS:\n",
      "   - Top 10 CVs are ranked by cross-encoder score\n",
      "   - Score colors:\n",
      "     * Green (>5) = strong match\n",
      "     * Gold (0-5) = moderate match\n",
      "     * Pink (<0) = weak match\n",
      "   - Matching skills are highlighted in green\n",
      "\n",
      "4. TAKE ACTIONS ON EACH CV:\n",
      "   - Contact (+1.0) - mark to reach out to candidate\n",
      "   - Shortlist (+0.5) - save for later review\n",
      "   - View Full CV (+0.3) - see complete CV text\n",
      "   - Skip (0) - pass for now\n",
      "   - Not a Match (-0.5) - mark as poor fit\n",
      "\n",
      "5. FEEDBACK LOOP:\n",
      "   - All actions are logged to the feedback database\n",
      "   - This feedback can be used to retrain the matching model\n",
      "   - Better matching over time\n",
      "\n",
      "TRY IT: Load sample_senior_python.txt from incoming/job/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# demo instructions\n",
    "print(\"\"\"\n",
    "RECRUITER MODE DEMO INSTRUCTIONS\n",
    "\n",
    "1. ENTER JOB POSTING:\n",
    "   - Paste job description text directly into the text area, OR\n",
    "   - Click \"Upload\" to select a PDF, DOCX, or TXT file\n",
    "\n",
    "2. CLICK \"Find Matching CVs!\" BUTTON\n",
    "\n",
    "3. REVIEW RESULTS:\n",
    "   - Top 10 CVs are ranked by cross-encoder score\n",
    "   - Score colors:\n",
    "     * Green (>5) = strong match\n",
    "     * Gold (0-5) = moderate match\n",
    "     * Pink (<0) = weak match\n",
    "   - Matching skills are highlighted in green\n",
    "\n",
    "4. TAKE ACTIONS ON EACH CV:\n",
    "   - Contact (+1.0) - mark to reach out to candidate\n",
    "   - Shortlist (+0.5) - save for later review\n",
    "   - View Full CV (+0.3) - see complete CV text\n",
    "   - Skip (0) - pass for now\n",
    "   - Not a Match (-0.5) - mark as poor fit\n",
    "\n",
    "5. FEEDBACK LOOP:\n",
    "   - All actions are logged to the feedback database\n",
    "   - This feedback can be used to retrain the matching model\n",
    "   - Better matching over time\n",
    "\n",
    "TRY IT: Load sample_senior_python.txt from incoming/job/\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_cvs() function defined\n",
      "\n",
      "Example usage:\n",
      "  results = search_cvs(\"Senior Python Developer with Django and AWS experience\")\n"
     ]
    }
   ],
   "source": [
    "# direct search function for programmatic use\n",
    "def search_cvs(job_text, top_k=10):\n",
    "    # direct search function for programmatic use\n",
    "    # Example:\n",
    "    #     results = search_cvs(\"Senior Python Developer with Django experience\")\n",
    "    \n",
    "    # Args:\n",
    "    #     job_text: job posting text\n",
    "    #     top_k: number of results\n",
    "    \n",
    "    # Returns:\n",
    "    #     list of match dicts with cv_id, cross_score, text\n",
    "    \n",
    "    # find candidates with bi-encoder\n",
    "    matches, fields = find_matching_cvs(job_text, top_k=50)\n",
    "    \n",
    "    # rerank with cross-encoder\n",
    "    reranked = rerank_cvs(job_text, matches, top_k=top_k)\n",
    "    \n",
    "    # display summary\n",
    "    print(f\"\\nJob: {fields['title']}\")\n",
    "    print(f\"Skills: {', '.join(fields['skills'][:5])}\")\n",
    "    print(f\"\\nTop {len(reranked)} matching CVs:\")\n",
    "    \n",
    "    for i, m in enumerate(reranked, 1):\n",
    "        print(f\"{i}. {m['cv_id']}: cross_score={m['cross_score']:.2f}\")\n",
    "        preview = m['text'][:80].replace(\"query:\", \"\").replace(\"Query:\", \"\").strip()\n",
    "        print(f\"   {preview}\")\n",
    "    \n",
    "    return reranked\n",
    "\n",
    "print(\"search_cvs() function defined\")\n",
    "print(\"\")\n",
    "print(\"Example usage:\")\n",
    "print('  results = search_cvs(\"Senior Python Developer with Django and AWS experience\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the widgets above to search, or call search_cvs() directly.\n"
     ]
    }
   ],
   "source": [
    "# test with sample job posting\n",
    "# uncomment to test\n",
    "\n",
    "# sample_path = os.path.join(PROJECT_ROOT, \"incoming/job/sample_senior_python.txt\")\n",
    "# with open(sample_path) as f:\n",
    "#     sample_job = f.read()\n",
    "# \n",
    "# results = search_cvs(sample_job, top_k=5)\n",
    "\n",
    "print(\"Use the widgets above to search, or call search_cvs() directly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talent-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
