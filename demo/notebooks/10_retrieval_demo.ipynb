{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/developer/project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# TWO levels\n",
    "cwd = os.getcwd()\n",
    "if 'notebooks' in cwd:\n",
    "    PROJECT_ROOT = os.path.dirname(os.path.dirname(cwd)) \n",
    "else:\n",
    "    PROJECT_ROOT = cwd\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/developer/project\n",
      "\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# check GPU\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from: /home/developer/project/training/output/models/cv-job-matcher-e5-best\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a7009258944289b427f7224d67ec37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-encoder loaded, embedding dim: 768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aba25c56a2425fb8e5d0f6c65652d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L12-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder loaded on cuda\n"
     ]
    }
   ],
   "source": "# check that trained model exists\n# use best sweep model if available, otherwise use initial training model\nMODEL_PATH = os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5-best\")\nif not os.path.exists(MODEL_PATH):\n    MODEL_PATH = os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\")\n    \nassert os.path.exists(f\"{MODEL_PATH}/config.json\"), \\\n    f\"Trained model not found at {MODEL_PATH} - run notebook 09 first!\"\nprint(f\"Using model from: {MODEL_PATH}\")\n\n# load trained bi-encoder\n# load with fp16 for faster inference\nbi_encoder = SentenceTransformer(\n    MODEL_PATH,\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    model_kwargs={\"torch_dtype\": torch.float16}  # fp16 precision\n)\nprint(f\"Bi-encoder loaded, embedding dim: {bi_encoder.get_sentence_embedding_dimension()}\")\n\n# load cross-encoder for reranking\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L12-v2\", device=device)\nprint(f\"Cross-encoder loaded on {device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs loaded: 165193\n",
      "Columns: ['job_id', 'embedding_text', 'embedding', 'isco_code']\n",
      "CVs loaded: 7299\n",
      "Columns: ['id', 'text']\n",
      "\n",
      "Sample Job\n",
      "passage: Role of $18.00 Assistant Manager at McDonald's in Whiteville, NC. Required skills: Leadership, Conflict management, Customer service, Problemsolving, Teamwork, Communication, Time management, Organization, Active listening, Problemsolving. Experience level: Mid-level, 3-5 years experience.\n",
      "\n",
      "Sample CV\n",
      "Query: I am a Python Developer with 0 years of experience, (internship level). My skills include: MySQL, C++, Python, Windows, Fedora, Ubuntu, C, Cent OS, Tensorflow, Numpy. I worked as Python Developer from 2026 (6 months). I completed my ME Computer Engineering at Savitribai Phule Pune University \n"
     ]
    }
   ],
   "source": [
    "# load job data with embeddings\n",
    "jobs_df = pd.read_parquet(os.path.join(PROJECT_ROOT, 'training', 'output', 'embeddings', 'jobs_embedded.parquet'))\n",
    "print(f\"Jobs loaded: {len(jobs_df)}\")\n",
    "print(f\"Columns: {jobs_df.columns.tolist()}\")\n",
    "\n",
    "# load CV data\n",
    "CV_DATA_PATH = os.path.join(PROJECT_ROOT, 'ingest_cv', 'output', 'cv_query_text.parquet')\n",
    "cvs_df = pd.read_parquet(CV_DATA_PATH)\n",
    "print(f\"CVs loaded: {len(cvs_df)}\")\n",
    "print(f\"Columns: {cvs_df.columns.tolist()}\")\n",
    "\n",
    "# show sample\n",
    "print(\"\\nSample Job\")\n",
    "print(jobs_df.iloc[0]['embedding_text'][:300])\n",
    "print(\"\\nSample CV\")\n",
    "print(cvs_df.iloc[0]['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create_lookups",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created lookups: 165193 jobs, 7299 CVs\n"
     ]
    }
   ],
   "source": [
    "# create lookup dictionaries for fast ID -> index mapping\n",
    "job_id_to_idx = {job_id: idx for idx, job_id in enumerate(jobs_df['job_id'])}\n",
    "cv_id_to_idx = {cv_id: idx for idx, cv_id in enumerate(cvs_df['id'])}\n",
    "\n",
    "print(f\"Created lookups: {len(job_id_to_idx)} jobs, {len(cv_id_to_idx)} CVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "build_job_index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job embeddings shape: (165193, 768)\n",
      "Embedding norms - mean: 1.0001, min: 0.9998, max: 1.0005\n",
      "Embeddings already normalized\n"
     ]
    }
   ],
   "source": [
    "# extract job embeddings from dataframe\n",
    "\n",
    "# embeddings stored as lists in parquet, need to convert to numpy array\n",
    "job_embeddings = np.array(jobs_df['embedding'].tolist(), dtype=np.float32)\n",
    "print(f\"Job embeddings shape: {job_embeddings.shape}\")\n",
    "\n",
    "# check if already normalized\n",
    "norms = np.linalg.norm(job_embeddings, axis=1)\n",
    "print(f\"Embedding norms - mean: {norms.mean():.4f}, min: {norms.min():.4f}, max: {norms.max():.4f}\")\n",
    "\n",
    "# normalize for cosine similarity via inner product\n",
    "if norms.mean() < 0.99 or norms.mean() > 1.01:\n",
    "    faiss.normalize_L2(job_embeddings)\n",
    "    norms = np.linalg.norm(job_embeddings, axis=1)\n",
    "    print(f\"After normalization - mean: {norms.mean():.4f}\")\n",
    "else:\n",
    "    print(\"Embeddings already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "create_job_faiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs Faiss index built:\n",
      " Vectors: 165193\n",
      " Dimension: 768\n",
      "Index saved to: output/indexes/jobs_index.faiss\n",
      "File size: 507.5 MB\n"
     ]
    }
   ],
   "source": "# create Faiss index\n# using IndexFlatIP (inner product) which equals cosine similarity for normalized vectors\ndimension = job_embeddings.shape[1]\njobs_index = faiss.IndexFlatIP(dimension)\njobs_index.add(job_embeddings)\n\nprint(f\"Jobs Faiss index built:\")\nprint(f\" Vectors: {jobs_index.ntotal}\")\nprint(f\" Dimension: {dimension}\")\n\n# save index\nos.makedirs('output/indexes', exist_ok=True)\nfaiss.write_index(jobs_index, os.path.join(PROJECT_ROOT, 'training', 'output', 'indexes', 'jobs_index.faiss'))\nprint(f\"Index saved to: output/indexes/jobs_index.faiss\")\nprint(f\"File size: {os.path.getsize(os.path.join(PROJECT_ROOT, 'training', 'output', 'indexes', 'jobs_index.faiss')) / 1e6:.1f} MB\")"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "encode_cvs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CV text (first 200 chars): query: I am a Python Developer with 0 years of experience, (internship level). My skills include: MySQL, C++, Python, Windows, Fedora, Ubuntu, C, Cent OS, Tensorflow, Numpy. I worked as Python Develop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46969d2c6aab4710aa15951d29b43135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV embeddings shape: (7299, 768)\n"
     ]
    }
   ],
   "source": [
    "# encode CVs with trained bi-encoder\n",
    "\n",
    "# !!! fix prefix case, cv data has \"Query: \" e5 needs lowercase \"query: \"\n",
    "cv_texts = []\n",
    "for text in cvs_df['text']:\n",
    "    # fix uppercase Query to lowercase query\n",
    "    if text.startswith(\"Query: \"):\n",
    "        text = \"query: \" + text[7:]\n",
    "    elif not text.startswith(\"query: \"):\n",
    "        text = \"query: \" + text\n",
    "    cv_texts.append(text)\n",
    "\n",
    "print(f\"Sample CV text (first 200 chars): {cv_texts[0][:200]}\")\n",
    "\n",
    "# encode in batches\n",
    "cv_embeddings = bi_encoder.encode(\n",
    "    cv_texts,\n",
    "    batch_size=256,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"\\nCV embeddings shape: {cv_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "create_cv_faiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVs Faiss index built:\n",
      " Vectors: 7299\n",
      " Dimension: 768\n",
      "Index saved to: output/indexes/cvs_index.faiss\n",
      "File size: 22.4 MB\n",
      "CV embeddings saved to: output/embeddings/cvs_embedded.parquet\n"
     ]
    }
   ],
   "source": "# normalize CV embeddings\nfaiss.normalize_L2(cv_embeddings)\n\n# create index\ncvs_index = faiss.IndexFlatIP(dimension)\ncvs_index.add(cv_embeddings)\nprint(f\"CVs Faiss index built:\")\nprint(f\" Vectors: {cvs_index.ntotal}\")\nprint(f\" Dimension: {dimension}\")\n# save index\nfaiss.write_index(cvs_index, os.path.join(PROJECT_ROOT, 'training', 'output', 'indexes', 'cvs_index.faiss'))\nprint(f\"Index saved to: output/indexes/cvs_index.faiss\")\nprint(f\"File size: {os.path.getsize(os.path.join(PROJECT_ROOT, 'training', 'output', 'indexes', 'cvs_index.faiss')) / 1e6:.1f} MB\")\n# also save CV embeddings for later use\ncv_embeddings_df = pd.DataFrame({\n    'cv_id': cvs_df['id'].tolist(),\n    'cv_text': cv_texts,\n    'embedding': list(cv_embeddings)\n})\ncv_embeddings_df.to_parquet(os.path.join(PROJECT_ROOT, 'training', 'output', 'embeddings', 'cvs_embedded.parquet'))\nprint(f\"CV embeddings saved to: output/embeddings/cvs_embedded.parquet\")"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cv_to_jobs_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV -> Jobs Retrieval\n",
      "\n",
      "Sample CV ID: A5021\n",
      "\n",
      "CV text (first 400 chars):\n",
      "query: I am a Professional with 9 years of experience, (principal level). My skills include: administrative, acrobat, adobe creative suite, photoshop, apple, approach, autocad, budgets, building codes, c, consulting, council, clientele, client, clients, fast, floor plans, illustrator, indesign, interior design, microsoft office suite, office, project management, quick, revit. I worked as SENIOR IN\n"
     ]
    }
   ],
   "source": [
    "print(\"CV -> Jobs Retrieval\")\n",
    "\n",
    "# pick a CV from test set (unseen during training)\n",
    "CV_SPLITS_PATH = os.path.join(PROJECT_ROOT, 'ingest_cv', 'output')\n",
    "test_cv_ids = pd.read_parquet(os.path.join(CV_SPLITS_PATH, 'test_set_cv_ids.parquet'))\n",
    "sample_cv_id = test_cv_ids.iloc[0]['anchor']\n",
    "# get CV text\n",
    "sample_cv_idx = cv_id_to_idx[sample_cv_id]\n",
    "sample_cv_text = cv_texts[sample_cv_idx]\n",
    "\n",
    "print(f\"\\nSample CV ID: {sample_cv_id}\")\n",
    "print(f\"\\nCV text (first 400 chars):\")\n",
    "print(sample_cv_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "retrieve_jobs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 jobs by bi-encoder similarity:\n",
      "\n",
      "1. B25769883829 (score: 0.3720)\n",
      "   passage: Role of SENIOR INTERIOR DESIGNER - Albany, Newburgh or Poughkeepsie, NY at CPL in Latham, NY. Required skills: Interior Design, AutoCAD, Revi...\n",
      "\n",
      "2. B51539693521 (score: 0.3636)\n",
      "   passage: Role of Senior Interior Designer at Flight Club Darts in London, England, United Kingdom. Required skills: Interior design, Architectural qua...\n",
      "\n",
      "3. B17179955207 (score: 0.3626)\n",
      "   passage: Role of Senior Interior Designer at Arianne Bellizaire Interiors, LLC in Baton Rouge, LA. Required skills: Interior Design, AutoCAD, SketchUp...\n",
      "\n",
      "4. B25769844860 (score: 0.3618)\n",
      "   passage: Role of Interior Designer | Residential Interiors at Interior Talent in Baltimore, MD. Required skills: Interior Design, AutoCAD, AutoCAD LT,...\n",
      "\n",
      "5. B94489321579 (score: 0.3577)\n",
      "   passage: Role of Interior Designer at HumanKapital Pty Ltd in Newcastle, New South Wales, Australia. Required skills: Interior Design, Revit, Photosho...\n",
      "showing top 5 of 50\n"
     ]
    }
   ],
   "source": [
    "# get CV embedding (already computed)\n",
    "cv_emb = cv_embeddings[sample_cv_idx:sample_cv_idx+1]\n",
    "# search top-50 jobs\n",
    "k = 50\n",
    "scores, indices = jobs_index.search(cv_emb, k)\n",
    "\n",
    "print(f\"Top {k} jobs by bi-encoder similarity:\")\n",
    "\n",
    "top_jobs = []\n",
    "for rank, (score, idx) in enumerate(zip(scores[0], indices[0]), 1):\n",
    "    job_id = jobs_df.iloc[idx]['job_id']\n",
    "    job_text = jobs_df.iloc[idx]['embedding_text']\n",
    "    top_jobs.append({\n",
    "        'rank': rank,\n",
    "        'job_id': job_id,\n",
    "        'bi_score': score,\n",
    "        'job_text': job_text,\n",
    "        'idx': idx\n",
    "    })\n",
    "    if rank <= 5:\n",
    "        print(f\"\\n{rank}. {job_id} (score: {score:.4f})\")\n",
    "        print(f\"   {job_text[:150]}...\")\n",
    "\n",
    "print(f\"showing top 5 of {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rerank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3bfab9811c4458a48dea37def75af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder scores computed for 50 candidates\n"
     ]
    }
   ],
   "source": [
    "# !!! cross-encoder does NOT use prefixes\n",
    "cv_text_plain = sample_cv_text.replace(\"query: \", \"\").replace(\"Query: \", \"\")\n",
    "\n",
    "# create pairs for cross-encoder\n",
    "pairs = []\n",
    "for job in top_jobs:\n",
    "    job_text_plain = job['job_text'].replace(\"passage: \", \"\")\n",
    "    pairs.append((cv_text_plain, job_text_plain))\n",
    "\n",
    "# score pairs\n",
    "cross_scores = cross_encoder.predict(pairs, batch_size=128, show_progress_bar=True)\n",
    "\n",
    "# add cross-encoder scores to results\n",
    "for job, cross_score in zip(top_jobs, cross_scores):\n",
    "    job['cross_score'] = float(cross_score)\n",
    "\n",
    "print(f\"Cross-encoder scores computed for {len(top_jobs)} candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "show_reranked",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 jobs AFTER cross-encoder reranking:\n",
      "\n",
      "1. B34359743644 (was rank 50, +49)\n",
      "  Bi-encoder: 0.3252 | Cross-encoder: -1.2945\n",
      "  passage: Role of Art Director at 24 Seven Talent in St Louis, MO. Required skills: Adobe Creative Suite, Photoshop, Illustrator, InDesign, Sketch, Dig...\n",
      "\n",
      "2. B25769844862 (was rank 43, +41)\n",
      "  Bi-encoder: 0.3273 | Cross-encoder: -2.2368\n",
      "  passage: Role of Interior Designer, Healthcare at Stantec in Los Angeles, CA. Required skills: Interior Design, Architecture, BIM, Revit, Enscape, Ado...\n",
      "\n",
      "3. B34359831152 (was rank 44, +41)\n",
      "  Bi-encoder: 0.3270 | Cross-encoder: -2.4375\n",
      "  passage: Role of Sr Interior Designer at Norton Creative in Houston, TX. Required skills: Interior Design, Architectural Drawings, Renderings, Restaur...\n",
      "\n",
      "4. B51539693521 (was rank 2, -2)\n",
      "  Bi-encoder: 0.3636 | Cross-encoder: -2.5292\n",
      "  passage: Role of Senior Interior Designer at Flight Club Darts in London, England, United Kingdom. Required skills: Interior design, Architectural qua...\n",
      "\n",
      "5. B17179955207 (was rank 3, -2)\n",
      "  Bi-encoder: 0.3626 | Cross-encoder: -3.1826\n",
      "  passage: Role of Senior Interior Designer at Arianne Bellizaire Interiors, LLC in Baton Rouge, LA. Required skills: Interior Design, AutoCAD, SketchUp...\n",
      "\n",
      "6. B17179910149 (was rank 14, +8)\n",
      "  Bi-encoder: 0.3437 | Cross-encoder: -3.2300\n",
      "  passage: Role of Interior Design Assistant at RH in West Palm Beach, FL. Required skills: Interior design, AutoCAD, Google Applications, Space plannin...\n",
      "\n",
      "7. B94489321569 (was rank 29, +22)\n",
      "  Bi-encoder: 0.3376 | Cross-encoder: -3.3312\n",
      "  passage: Role of Interior Design Coordinator I at HDR in Tampa, FL. Required skills: Interior Design, Interior Architecture, Revit, AutoCAD, Adobe Cre...\n",
      "\n",
      "8. B8589975720 (was rank 34, +26)\n",
      "  Bi-encoder: 0.3361 | Cross-encoder: -3.3843\n",
      "  passage: Role of Interior Designer | Intermediate at RH in Annapolis, MD. Required skills: Design, AutoCAD, Adobe Creative Suite, Space planning, Rend...\n",
      "\n",
      "9. B85899387134 (was rank 28, +19)\n",
      "  Bi-encoder: 0.3382 | Cross-encoder: -3.4852\n",
      "  passage: Role of Interior Designer at Burdett Hill Group in Fort Worth, TX. Required skills: Interior Design, LEED AP, WELL AP, Revit, AutoCAD, Adobe ...\n",
      "\n",
      "10. B34359741813 (was rank 33, +23)\n",
      "  Bi-encoder: 0.3363 | Cross-encoder: -3.5513\n",
      "  passage: Role of Administrative Assistant at Creative Planning in Oakbrook Terrace, IL. Required skills: Microsoft Office, Word, Outlook, Excel, Datab...\n",
      "BEST MATCH: B34359743644\n",
      "Cross-encoder score: -1.2945\n"
     ]
    }
   ],
   "source": [
    "# sort by cross-encoder score\n",
    "reranked = sorted(top_jobs, key=lambda x: x['cross_score'], reverse=True)\n",
    "print(\"Top 10 jobs AFTER cross-encoder reranking:\")\n",
    "\n",
    "for new_rank, job in enumerate(reranked[:10], 1):\n",
    "    old_rank = job['rank']\n",
    "    change = old_rank - new_rank\n",
    "    change_str = f\"+{change}\" if change > 0 else str(change)\n",
    "    \n",
    "    print(f\"\\n{new_rank}. {job['job_id']} (was rank {old_rank}, {change_str})\")\n",
    "    print(f\"  Bi-encoder: {job['bi_score']:.4f} | Cross-encoder: {job['cross_score']:.4f}\")\n",
    "    print(f\"  {job['job_text'][:150]}...\")\n",
    "\n",
    "print(f\"BEST MATCH: {reranked[0]['job_id']}\")\n",
    "print(f\"Cross-encoder score: {reranked[0]['cross_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "job_to_cvs_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job -> CVs Retrieval\n",
      "\n",
      "Sample Job ID: B77309436369\n",
      "\n",
      "Job text (first 400 chars):\n",
      "passage: Role of Director of ICU, Registered Nurse (RN) at Prime Healthcare at Health eCareers in Inglewood, CA. Required skills: Registered Nurse, BLS (AHA), ACLS (AHA), CCRN certificate, PALS (AHA), Supervisory/management skills, Clinical experience, Bachelor's of Science in Nursing (BSN), Communication skills, Collaboration skills. Experience level: Lead level, 7+ years experience with leadersh\n"
     ]
    }
   ],
   "source": [
    "print(\"Job -> CVs Retrieval\")\n",
    "\n",
    "# pick a random job\n",
    "np.random.seed(42)\n",
    "sample_job_idx = np.random.randint(len(jobs_df))\n",
    "sample_job = jobs_df.iloc[sample_job_idx]\n",
    "sample_job_id = sample_job['job_id']\n",
    "sample_job_text = sample_job['embedding_text']\n",
    "\n",
    "print(f\"\\nSample Job ID: {sample_job_id}\")\n",
    "print(f\"\\nJob text (first 400 chars):\")\n",
    "print(sample_job_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "retrieve_cvs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 CVs for this job:\n",
      "\n",
      "1. CV A5474 (score: 0.4925)\n",
      "   query: I am a Professional with 0 years of experience, (internship level).\n",
      "\n",
      "2. CV A5952 (score: 0.4408)\n",
      "   query: I am a Consultant with 0 years of experience, (internship level).\n",
      "\n",
      "3. CV A5689 (score: 0.4355)\n",
      "   query: I am a Professional with 24 years of experience, (principal level). My skills include: asc, qa, emr, pharmacy, infection control, metrics, risk management, satisfaction, staffing, trading, trai\n",
      "\n",
      "4. CV A5344 (score: 0.4223)\n",
      "   query: I am a Professional with 15 years of experience, (principal level). My skills include: excel, powerpoint). I worked as Professional from 09/2013 to Current in . I worked as Dancer for Chicago L\n",
      "\n",
      "5. CV A5368 (score: 0.4126)\n",
      "   query: I am a Mist with 25 years of experience, (principal level). My skills include: phlebotomy knowledge, hippa compliance, blood bank background, clia & osha compliance, sharp critical thinker, man\n",
      "\n",
      "6. CV A5590 (score: 0.4069)\n",
      "   query: I am a Emergency room admitting specialist/quality assurance with 18 years of experience, (principal level). My skills include: bilingual, speak, microsoft, explorer, lotus, and outlook, midas.\n",
      "\n",
      "7. CV A5609 (score: 0.4001)\n",
      "   query: I am a Licensed practical nurse- step-down unit with 5 years of experience, (mid-level). I worked as Licensed Practical Nurse- Step-down Unit from 01/2017 to 09/2017 in . I worked as License Pr\n",
      "\n",
      "8. CV A5636 (score: 0.3990)\n",
      "   query: I am a Professional with 22 years of experience, (principal level). My skills include: cpr and first aid, macro counting, excel, powerpoint, oracle, sales, customer service, investments, organi\n",
      "\n",
      "9. CV A5523 (score: 0.3959)\n",
      "   query: I am a Professional with 19 years of experience, (principal level). My skills include: arts, assisted living, cna, coaching, customer service, financial, home health, nursing, receiving, shippi\n",
      "\n",
      "10. CV A5623 (score: 0.3948)\n",
      "   query: I am a Professional with 20 years of experience, (principal level). My skills include: billing, blood pressure, brochures, communication skills, clients, email, goal setting, promote health, le\n"
     ]
    }
   ],
   "source": [
    "# get job embedding\n",
    "job_emb = job_embeddings[sample_job_idx:sample_job_idx+1]\n",
    "# search top CVs\n",
    "k_cvs = 10\n",
    "scores, indices = cvs_index.search(job_emb, k_cvs)\n",
    "print(f\"Top {k_cvs} CVs for this job:\")\n",
    "\n",
    "for rank, (score, idx) in enumerate(zip(scores[0], indices[0]), 1):\n",
    "    cv_id = cvs_df.iloc[idx]['id']\n",
    "    cv_text = cv_texts[idx]\n",
    "    print(f\"\\n{rank}. CV {cv_id} (score: {score:.4f})\")\n",
    "    print(f\"   {cv_text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compute_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on 730 validation pairs\n",
      "Columns: ['anchor', 'match']\n",
      "Sample pair: CV A1 -> Job B42949739960\n"
     ]
    }
   ],
   "source": [
    "# load validation pairs (CV -> Job ground truth)\n",
    "val_pairs = pd.read_parquet(os.path.join(PROJECT_ROOT, 'training', 'output', 'training_data', 'validation_pairs.parquet'))\n",
    "print(f\"\\nEvaluating on {len(val_pairs)} validation pairs\")\n",
    "print(f\"Columns: {val_pairs.columns.tolist()}\")\n",
    "print(f\"Sample pair: CV {val_pairs.iloc[0]['anchor']} -> Job {val_pairs.iloc[0]['match']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recall_at_k",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing recall: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 730/730 [00:07<00:00, 97.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on 730 validation pairs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute recall@k\n",
    "hits_at_1 = 0\n",
    "hits_at_5 = 0\n",
    "hits_at_10 = 0\n",
    "hits_at_50 = 0\n",
    "total = 0\n",
    "\n",
    "for _, row in tqdm(val_pairs.iterrows(), total=len(val_pairs), desc=\"Computing recall\"):\n",
    "    cv_id = row['anchor']\n",
    "    true_job_id = row['match']\n",
    "    \n",
    "    # get CV index\n",
    "    cv_idx = cv_id_to_idx.get(cv_id)\n",
    "    if cv_idx is None:\n",
    "        continue\n",
    "    \n",
    "    # get CV embedding\n",
    "    cv_emb = cv_embeddings[cv_idx:cv_idx+1]\n",
    "    \n",
    "    # search\n",
    "    _, indices = jobs_index.search(cv_emb, 50)\n",
    "    retrieved_job_ids = [jobs_df.iloc[idx]['job_id'] for idx in indices[0]]\n",
    "    \n",
    "    # check if true job in retrieved\n",
    "    if true_job_id in retrieved_job_ids[:1]:\n",
    "        hits_at_1 += 1\n",
    "    if true_job_id in retrieved_job_ids[:5]:\n",
    "        hits_at_5 += 1\n",
    "    if true_job_id in retrieved_job_ids[:10]:\n",
    "        hits_at_10 += 1\n",
    "    if true_job_id in retrieved_job_ids[:50]:\n",
    "        hits_at_50 += 1\n",
    "    \n",
    "    total += 1\n",
    "\n",
    "print(f\"Results on {total} validation pairs:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "show_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall Metrics:\n",
      "\n",
      "Recall@1:  0.0959 (70/730)\n",
      "Recall@5:  0.2877 (210/730)\n",
      "Recall@10: 0.4096 (299/730)\n",
      "Recall@50: 0.6932 (506/730)\n",
      "Interpretation:\n",
      "- Recall@50 > 0.3 bi-encoder retrieves relevant job\n",
      "- Recall@10 > 0.2 good ranking quality\n",
      "- Recall@1 shows exact top match accuracy\n"
     ]
    }
   ],
   "source": [
    "# display metrics\n",
    "print(\"\\nRecall Metrics:\")\n",
    "recall_1 = hits_at_1 / total if total > 0 else 0\n",
    "recall_5 = hits_at_5 / total if total > 0 else 0\n",
    "recall_10 = hits_at_10 / total if total > 0 else 0\n",
    "recall_50 = hits_at_50 / total if total > 0 else 0\n",
    "\n",
    "print(f\"\\nRecall@1:  {recall_1:.4f} ({hits_at_1}/{total})\")\n",
    "print(f\"Recall@5:  {recall_5:.4f} ({hits_at_5}/{total})\")\n",
    "print(f\"Recall@10: {recall_10:.4f} ({hits_at_10}/{total})\")\n",
    "print(f\"Recall@50: {recall_50:.4f} ({hits_at_50}/{total})\")\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Recall@50 > 0.3 bi-encoder retrieves relevant job\")\n",
    "print(\"- Recall@10 > 0.2 good ranking quality\")\n",
    "print(\"- Recall@1 shows exact top match accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "match_function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_cv_to_jobs() function defined\n",
      "\n",
      "Usage: match_cv_to_jobs('your CV text here', top_k=10, rerank=True)\n"
     ]
    }
   ],
   "source": [
    "def match_cv_to_jobs(cv_text, top_k=10, rerank=True):\n",
    "    # match a CV to jobs.\n",
    "    # Args:\n",
    "    #     cv_text: CV text (will add prefix if not present)\n",
    "    #     top_k: Number of matches to return\n",
    "    #     rerank: Whether to rerank with cross-encoder\n",
    "    # returns list of dicts with job_id, score, job_text, ensure lowercase prefix\n",
    "\n",
    "    if cv_text.startswith(\"Query: \"):\n",
    "        cv_text = \"query: \" + cv_text[7:]\n",
    "    elif not cv_text.startswith(\"query: \"):\n",
    "        cv_text = \"query: \" + cv_text\n",
    "    \n",
    "    # encode CV\n",
    "    cv_emb = bi_encoder.encode([cv_text], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(cv_emb)\n",
    "    \n",
    "    # retrieve candidates\n",
    "    n_candidates = 50 if rerank else top_k\n",
    "    scores, indices = jobs_index.search(cv_emb, n_candidates)\n",
    "    \n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        job_id = jobs_df.iloc[idx]['job_id']\n",
    "        job_text = jobs_df.iloc[idx]['embedding_text']\n",
    "        results.append({\n",
    "            'job_id': job_id,\n",
    "            'bi_score': float(score),\n",
    "            'job_text': job_text\n",
    "        })\n",
    "    \n",
    "    if rerank:\n",
    "        # cross-encoder reranking (no prefixes)\n",
    "        cv_plain = cv_text.replace(\"query: \", \"\")\n",
    "        pairs = [(cv_plain, r['job_text'].replace(\"passage: \", \"\")) for r in results]\n",
    "        cross_scores = cross_encoder.predict(pairs, batch_size=128)\n",
    "        \n",
    "        for r, cs in zip(results, cross_scores):\n",
    "            r['cross_score'] = float(cs)\n",
    "        \n",
    "        results = sorted(results, key=lambda x: x['cross_score'], reverse=True)\n",
    "    \n",
    "    return results[:top_k]\n",
    "\n",
    "print(\"match_cv_to_jobs() function defined\")\n",
    "print(\"\\nUsage: match_cv_to_jobs('your CV text here', top_k=10, rerank=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "test_interactive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "\n",
      "Test CV: python developer with 5 years experience in Django and PostgreSQL. Machine learning knowledge. AWS and Docker.\n",
      "\n",
      "Top 5 matches:\n",
      "\n",
      "1. B42949739969 (score: 6.5764)\n",
      "   passage: Role of Python/Django Application Developer at Pinnacle Group, Inc. in Sunnyvale, CA. Required skills: Python, Django Application Development, Django REST Frameworks, AWS, Terraform, Kubernet\n",
      "\n",
      "2. B83861 (score: 6.0618)\n",
      "   passage: Role of Senior Backend and Cloud Engineer - Machine Learning Infrastructure (Python) at Scandit in Manchester, England, United Kingdom. Required skills: Python, Django, PostgreSQL, PubSub, Ku\n",
      "\n",
      "3. B8590019329 (score: 5.1674)\n",
      "   passage: Role of Senior Developer at Atlas UP in Los Angeles, CA. Required skills: Python, Django, PostgreSQL, Redis, AWS, Langchain, Pandas, DevOps, Agile, Problemsolving. Experience level: Senior le\n",
      "\n",
      "4. B60129609256 (score: 4.8360)\n",
      "   passage: Role of Python Django Web Developer-locals at Steneral Consulting in Waukegan, IL. Required skills: Python, Django, Docker, Jenkins, Linux, Plotly Dash, Async backend process, Job scheduler, \n",
      "\n",
      "5. B88429 (score: 3.9471)\n",
      "   passage: Role of Senior Software Developer at Anthesis Group in Edinburgh, Scotland, United Kingdom. Required skills: Django, Python, JavaScript, CSS, AJAX, SQL, MySQL, PostgreSQL, Linux, Analytical s\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "print(\"TEST\")\n",
    "\n",
    "test_cv = \"python developer with 5 years experience in Django and PostgreSQL. Machine learning knowledge. AWS and Docker.\"\n",
    "print(f\"\\nTest CV: {test_cv}\")\n",
    "\n",
    "matches = match_cv_to_jobs(test_cv, top_k=5, rerank=True)\n",
    "\n",
    "print(f\"\\nTop 5 matches:\")\n",
    "for i, m in enumerate(matches, 1):\n",
    "    score = m.get('cross_score', m['bi_score'])\n",
    "    print(f\"\\n{i}. {m['job_id']} (score: {score:.4f})\")\n",
    "    print(f\"   {m['job_text'][:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "test_another",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test CV: marketing manager with 10 years experience in digital marketing, social media, and brand strategy\n",
      "\n",
      "Top 5 matches:\n",
      "\n",
      "1. B85899370672 (score: 7.5013)\n",
      "   passage: Role of Digital Marketing Manager at Cross Resource Group in Houston, TX. Required skills: Digital Marketing, Social Media Management, Brand Strategy, Analytics, Organic Social Media, Paid So...\n",
      "\n",
      "2. B68719487908 (score: 7.1493)\n",
      "   passage: Role of Brand Marketing Manager at Perry Ellis International in New York, NY. Required skills: Social media marketing, Social media strategy, Creative strategy, Budget management, Media plann...\n",
      "\n",
      "3. B77309437074 (score: 6.7741)\n",
      "   passage: Role of E-commerce and Digital Marketing Manager at Brand Recruitment in Basingstoke, England, United Kingdom. Required skills: Shopify, SEO, PPC, Email Marketing, Digital Marketing, Ecommerc...\n",
      "\n",
      "4. B8590025957 (score: 6.5766)\n",
      "   passage: Role of Social Media Manager at Board in London, England, United Kingdom. Required skills: Social Media Management, Content Creation, Online Presence, Customer Engagement, Analytics, Digital ...\n",
      "\n",
      "5. B8590020848 (score: 6.5276)\n",
      "   passage: Role of Senior Manager, Digital Marketing & Strategy (Philanthropy) at Live Nation Entertainment in New York, NY. Required skills: Content Marketing, Client Management, Content Management, An...\n"
     ]
    }
   ],
   "source": [
    "# try another CV\n",
    "test_cv2 = \"marketing manager with 10 years experience in digital marketing, social media, and brand strategy\"\n",
    "print(f\"\\nTest CV: {test_cv2}\")\n",
    "\n",
    "matches2 = match_cv_to_jobs(test_cv2, top_k=5, rerank=True)\n",
    "\n",
    "print(f\"\\nTop 5 matches:\")\n",
    "for i, m in enumerate(matches2, 1):\n",
    "    score = m.get('cross_score', m['bi_score'])\n",
    "    print(f\"\\n{i}. {m['job_id']} (score: {score:.4f})\")\n",
    "    print(f\"   {m['job_text'][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talent_matching_linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}