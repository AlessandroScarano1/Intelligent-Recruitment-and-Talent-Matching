{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Find project root (cv-job-matcher-project/)\n",
    "# Notebooks are at */notebooks/ so we need to go up TWO levels\n",
    "cwd = os.getcwd()\n",
    "if 'notebooks' in cwd:\n",
    "    PROJECT_ROOT = os.path.dirname(os.path.dirname(cwd))  # TWO levels up\n",
    "else:\n",
    "    PROJECT_ROOT = cwd\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick_mode_toggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK_MODE toggle for demo/testing\n",
    "# when True: single training run with best hyperparams (lr=5e-05, warmup=0.05)\n",
    "# when False: full hyperparameter sweep (6 combinations)\n",
    "\n",
    "QUICK_MODE = True  # set to False for full hyperparameter sweep\n",
    "\n",
    "# best hyperparameters from sweep (user specified)\n",
    "BEST_LR = 5e-05\n",
    "BEST_WARMUP = 0.05\n",
    "\n",
    "if QUICK_MODE:\n",
    "    print(f'QUICK_MODE enabled: single run with lr={BEST_LR}, warmup={BEST_WARMUP}')\n",
    "else:\n",
    "    print('FULL MODE: running hyperparameter sweep (6 combinations)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f223c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous sweep results found\n",
      "\n",
      "No initial training model found\n",
      "\n",
      "✓ Ready for fresh sweep\n"
     ]
    }
   ],
   "source": [
    "# Clean up previous sweep results before starting new sweep\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "sweep_dir = \"output/models/sweep\"\n",
    "if os.path.exists(sweep_dir):\n",
    "    print(f\"Found existing sweep directory with:\")\n",
    "    for item in os.listdir(sweep_dir):\n",
    "        print(f\"  - {item}\")\n",
    "    shutil.rmtree(sweep_dir)\n",
    "    print(f\"\\nDeleted {sweep_dir}\")\n",
    "else:\n",
    "    print(\"No previous sweep results found\")\n",
    "\n",
    "# Also clean initial training model\n",
    "initial_dir = os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\")\n",
    "if os.path.exists(initial_dir):\n",
    "    print(f\"\\nDeleting initial training model at: {initial_dir}\")\n",
    "    shutil.rmtree(initial_dir)\n",
    "    print(\"Deleted\")\n",
    "else:\n",
    "    print(\"\\nNo initial training model found\")\n",
    "\n",
    "# Clean best model copy if exists\n",
    "best_dir = os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5-best\")\n",
    "if os.path.exists(best_dir):\n",
    "    print(f\"\\nDeleting previous best model at: {best_dir}\")\n",
    "    shutil.rmtree(best_dir)\n",
    "    print(\"Deleted\")\n",
    "\n",
    "# Optional: clean local wandb logs (your runs are still saved online)\n",
    "wandb_dir = \"wandb\"\n",
    "if os.path.exists(wandb_dir):\n",
    "    print(f\"\\nDeleting local W&B logs at: {wandb_dir}\")\n",
    "    shutil.rmtree(wandb_dir)\n",
    "    print(\"Deleted (online logs preserved at wandb.ai)\")\n",
    "\n",
    "print(\"\\n✓ Ready for fresh sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wuzf4w1gmi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/developer/project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/27 02:28:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped lingering Spark session\n",
      "\n",
      "System memory:\n",
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:            30Gi        15Gi       1.5Gi       297Mi        13Gi        12Gi\n",
      "Swap:           19Gi       3.1Gi        16Gi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set working directory to project root\n",
    "import os\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# kill any lingering Spark sessions to free RAM\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.stop()\n",
    "    print(\"Stopped lingering Spark session\")\n",
    "except:\n",
    "    print(\"No Spark session to stop\")\n",
    "\n",
    "# check available memory\n",
    "import subprocess\n",
    "result = subprocess.run(['free', '-h'], capture_output=True, text=True)\n",
    "print(f\"\\nSystem memory:\\n{result.stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: WANDB_API_KEY not set in environment\n",
      "Either set it with: export WANDB_API_KEY=your_key_here\n",
      "Or run: wandb login\n",
      "\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "VRAM: 25.3 GB\n",
      "\n",
      "Training data found, ready to proceed\n"
     ]
    }
   ],
   "source": [
    "from nbconvert import export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import gc\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss, MatryoshkaLoss\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "    \n",
    "#CHECK: W&B API Key\n",
    "if 'WANDB_API_KEY' not in os.environ:\n",
    "    print(\"WARNING: WANDB_API_KEY not set in environment\")\n",
    "    print(\"Either set it with: export WANDB_API_KEY=your_key_here\")\n",
    "    print(\"Or run: wandb login\")\n",
    "else:\n",
    "    print(\"WANDB_API_KEY found in environment\")\n",
    "\n",
    "# Check GPU\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"!!!No GPU available, training will be slow\")\n",
    "\n",
    "# CHECK: training data from Plan 01\n",
    "assert os.path.exists(os.path.join(PROJECT_ROOT, 'training', 'output', 'training_data', 'training_dataset.parquet')), \\\n",
    "    \"training data not found, run 08 first\"\n",
    "print(\"\\nTraining data found, ready to proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5839\n",
      "Validation samples: 730\n",
      "\n",
      "Sample training pair:\n",
      "CV (anchor): query: I am a Devops Engineer with 3 years of experience, (mid-level). My skills include: GitLab, C++, English, Go, REST, Google Cloud, fluent, MongoDB, AWS, Agile, GraphQL, PostgreSQL, Jenkins, CI/CD, Node.js, Java, Django. I worked as Devops Engineer from 2019 2022 (N/A). I worked as Devops Engine...\n",
      "Job (positive): passage: Role of DevOps/Software Engineer III at Steneral Consulting in Houston, TX. Required skills: Python, CI/CD, Azure DevOps, Jenkins, GitLab, Kubernetes, Helm, Ansible, Chef, Puppet. Experience level: Mid-level, 3-5 years experience....\n"
     ]
    }
   ],
   "source": [
    "# load training data from previous output\n",
    "train_df = pd.read_parquet(os.path.join(PROJECT_ROOT, 'training', 'output', 'training_data', 'training_dataset.parquet'))\n",
    "val_df = pd.read_parquet(os.path.join(PROJECT_ROOT, 'training', 'output', 'training_data', 'validation_dataset.parquet'))\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# show sample\n",
    "print(\"\\nSample training pair:\")\n",
    "print(f\"CV (anchor): {train_df.iloc[0]['anchor_text'][:300]}...\")\n",
    "print(f\"Job (positive): {train_df.iloc[0]['positive_text'][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create_datasets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: Dataset({\n",
      "    features: ['anchor', 'positive'],\n",
      "    num_rows: 5839\n",
      "})\n",
      "val dataset: Dataset({\n",
      "    features: ['anchor', 'positive'],\n",
      "    num_rows: 730\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# !!! sentence-transformers v3 uses Dataset, NOT InputExample\n",
    "# column names must be 'anchor' and 'positive' for MNR loss\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"anchor\": train_df['anchor_text'].tolist(),\n",
    "    \"positive\": train_df['positive_text'].tolist()\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"anchor\": val_df['anchor_text'].tolist(),\n",
    "    \"positive\": val_df['positive_text'].tolist()\n",
    "})\n",
    "\n",
    "print(f\"train dataset: {train_dataset}\")\n",
    "print(f\"val dataset: {val_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "init_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e5-base-v2 model\n",
      "Model embedding dimension: 768\n",
      "Configured MNR + MatryoshkaLoss\n"
     ]
    }
   ],
   "source": [
    "# load base model\n",
    "print(\"Loading e5-base-v2 model\")\n",
    "model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "print(f\"Model embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# MNR loss (uses in-batch negatives)\n",
    "base_loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# wrap with MatryoshkaLoss for multi-dimension training\n",
    "loss = MatryoshkaLoss(\n",
    "    model=model,\n",
    "    loss=base_loss,\n",
    "    matryoshka_dims=[768, 512, 256, 128, 64]  # train at all these dimensions\n",
    ")\n",
    "print(\"Configured MNR + MatryoshkaLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_args",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments configured\n",
      " epochs: 10\n",
      " batch size: 64\n",
      " learning rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "# training arguments (SentenceTransformerTrainer uses HF Trainer backend)\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\"),\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,  # fp16\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,  # 10% warmup to avoid forgetting\n",
    "    fp16=True,  # mixed precision for speed\n",
    "\n",
    "    # evaluation\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,  # keep only best checkpoint\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    # logging\n",
    "    logging_steps=10,\n",
    "    run_name=\"cv-job-e5-mnr-matryoshka\",  # W&B run name\n",
    "\n",
    "    # Early stopping via Trainer\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    ")\n",
    "\n",
    "print(\"Training arguments configured\")\n",
    "print(f\" epochs: {args.num_train_epochs}\")\n",
    "print(f\" batch size: {args.per_device_train_batch_size}\")\n",
    "print(f\" learning rate: {args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wandb_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/developer/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mscaranoalex\u001b[0m (\u001b[33mscaranoalex-university-of-trento\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_022856-3225ik34</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34' target=\"_blank\">cv-job-e5-mnr-matryoshka</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B initialized: https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34\n"
     ]
    }
   ],
   "source": [
    "# initialize W&B\n",
    "# will prompt for login if WANDB_API_KEY not set\n",
    "wandb.init(\n",
    "    project=\"talent-matching\",\n",
    "    name=\"cv-job-e5-mnr-matryoshka\",\n",
    "    config={\n",
    "        \"model\": \"intfloat/e5-base-v2\",\n",
    "        \"loss\": \"MNR+Matryoshka\",\n",
    "        \"matryoshka_dims\": [768, 512, 256, 128, 64],\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"epochs\": 10,\n",
    "        \"train_samples\": len(train_df),\n",
    "        \"val_samples\": len(val_df)\n",
    "    }\n",
    ")\n",
    "print(f\"W&B initialized: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1230cbba73af472f8038cfc7f2401307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with early stopping (patience=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='736' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [736/920 06:32 < 01:38, 1.87 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.408500</td>\n",
       "      <td>1.238130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.885000</td>\n",
       "      <td>1.121766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.231900</td>\n",
       "      <td>1.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.809300</td>\n",
       "      <td>1.129452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.465700</td>\n",
       "      <td>1.071146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.336100</td>\n",
       "      <td>1.081982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.067500</td>\n",
       "      <td>1.105268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.868600</td>\n",
       "      <td>1.116916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Best validation loss: 1.0711\n",
      "Epochs trained: 8\n"
     ]
    }
   ],
   "source": [
    "# early stopping callback, stops if val loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "# trainer with early stopping\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    loss=loss,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# train\n",
    "print(\"Starting training with early stopping (patience=3)\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "print(f\"Best validation loss: {trainer.state.best_metric:.4f}\")\n",
    "print(f\"Epochs trained: {trainer.state.epoch:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "save_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: output/models/cv-job-matcher-e5\n",
      "  2_Normalize: 0.0 MB\n",
      "  README.md: 0.0 MB\n",
      "  model.safetensors: 438.0 MB\n",
      "  tokenizer.json: 0.7 MB\n",
      "  config.json: 0.0 MB\n",
      "  sentence_bert_config.json: 0.0 MB\n",
      "  modules.json: 0.0 MB\n",
      "  tokenizer_config.json: 0.0 MB\n",
      "  checkpoint-460: 0.0 MB\n",
      "  vocab.txt: 0.2 MB\n",
      "  special_tokens_map.json: 0.0 MB\n",
      "  1_Pooling: 0.0 MB\n",
      "  config_sentence_transformers.json: 0.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▃▃▁▁▂▃</td></tr><tr><td>eval/runtime</td><td>█▂▁▄▁▅▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█▅█▄▆▆</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█▅█▄▆▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▄█▄▂▃▃▃▃▄▂▄▂▂▂▂▁▁▃▃▃▂▂▃▄▄▁▆▁▂▂▁▂▄▂▁▃▁▃▄▂</td></tr><tr><td>train/learning_rate</td><td>▁▃▄▅▇████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂</td></tr><tr><td>train/loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.11692</td></tr><tr><td>eval/runtime</td><td>1.7425</td></tr><tr><td>eval/samples_per_second</td><td>418.948</td></tr><tr><td>eval/steps_per_second</td><td>52.799</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>736</td></tr><tr><td>train/grad_norm</td><td>33.20267</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8686</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cv-job-e5-mnr-matryoshka</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching/runs/3225ik34</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_022856-3225ik34/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save(os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\"))\n",
    "print(f\"Model saved to: {os.path.join(PROJECT_ROOT, 'training', 'output', 'models', 'cv-job-matcher-e5')}\")\n",
    "\n",
    "# list saved files\n",
    "import os\n",
    "for f in os.listdir(os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\")):\n",
    "    size = os.path.getsize(os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\", f)) / 1e6\n",
    "    print(f\"  {f}: {size:.1f} MB\")\n",
    "\n",
    "# finish W&B run\n",
    "wandb.finish()\n",
    "print(\"W&B run finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "test_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample similarity: 0.8006\n",
      "(Higher is better, expect > 0.7 for good match)\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "trained_model = SentenceTransformer(os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5\"))\n",
    "\n",
    "# encode a sample CV and job\n",
    "sample_cv = \"query: python developer with 5 years experience in Django and PostgreSQL\"\n",
    "sample_job = \"passage: Title: Senior Python Developer. Required: Python, Django, PostgreSQL, 5+ years experience\"\n",
    "\n",
    "cv_emb = trained_model.encode(sample_cv)\n",
    "job_emb = trained_model.encode(sample_job)\n",
    "\n",
    "# compute similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity([cv_emb], [job_emb])[0][0]\n",
    "print(f\"Sample similarity: {sim:.4f}\")\n",
    "print(\"(Higher is better, expect > 0.7 for good match)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7y1ngcpru8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep will run 6 experiments:\n",
      "  learning rates: [2e-05, 1e-05, 5e-06]\n",
      "  warmup ratios: [0.1, 0.05]\n",
      "  max epochs per run: 13\n",
      "  early stopping patience: 3\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter sweep configuration, controlled by QUICK_MODE\n",
    "if QUICK_MODE:\n",
    "    # single run with best hyperparameters\n",
    "    LEARNING_RATES = [BEST_LR]\n",
    "    WARMUP_RATIOS = [BEST_WARMUP]\n",
    "    SWEEP_EPOCHS = 9\n",
    "    SWEEP_PATIENCE = 3\n",
    "else:\n",
    "    # full sweep\n",
    "    LEARNING_RATES = [2e-5, 1e-5, 5e-6]\n",
    "    WARMUP_RATIOS = [0.1, 0.05]\n",
    "    SWEEP_EPOCHS = 13\n",
    "    SWEEP_PATIENCE = 3\n",
    "\n",
    "total_runs = len(LEARNING_RATES) * len(WARMUP_RATIOS)\n",
    "print(f\"Sweep will run {total_runs} experiments:\")\n",
    "print(f\"  learning rates: {LEARNING_RATES}\")\n",
    "print(f\"  warmup ratios: {WARMUP_RATIOS}\")\n",
    "print(f\"  max epochs per run: {SWEEP_EPOCHS}\")\n",
    "print(f\"  early stopping patience: {SWEEP_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7dd133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up initial training objects\n",
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 1/6: lr=2e-05, warmup=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_023534-zcjrisrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/zcjrisrd' target=\"_blank\">sweep_lr2e-05_warmup0.1</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/zcjrisrd' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/zcjrisrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec8ea79765d4188ada8bb06b9a37618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='736' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 736/1196 06:32 < 04:05, 1.87 it/s, Epoch 8/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.557200</td>\n",
       "      <td>1.245936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.209700</td>\n",
       "      <td>1.137908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.608300</td>\n",
       "      <td>1.123663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.941100</td>\n",
       "      <td>1.127357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.499400</td>\n",
       "      <td>1.088344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.462800</td>\n",
       "      <td>1.092251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.133200</td>\n",
       "      <td>1.118051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.025300</td>\n",
       "      <td>1.102149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0883, epochs=8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▃▃▁▁▂▂</td></tr><tr><td>eval/runtime</td><td>▄█▆▁▆▆▇▇</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▃█▃▃▂▂</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▃█▃▃▂▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▂▃▃▃▃▄▃▅▃▃▅▄▃▆▂▄▄▃▄▅▂▇▄▃▁▂▂▃▃▃▄▃▂▅▃</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▅▇█████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.10215</td></tr><tr><td>eval/runtime</td><td>1.7724</td></tr><tr><td>eval/samples_per_second</td><td>411.881</td></tr><tr><td>eval/steps_per_second</td><td>51.908</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>736</td></tr><tr><td>train/grad_norm</td><td>27.682</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>2.0253</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr2e-05_warmup0.1</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/zcjrisrd' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/zcjrisrd</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_023534-zcjrisrd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 2/6: lr=2e-05, warmup=0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_024214-bbakm04i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/bbakm04i' target=\"_blank\">sweep_lr2e-05_warmup0.05</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/bbakm04i' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/bbakm04i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a803ef18d1a1434eb27f49e26c5247a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='736' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 736/1196 06:38 < 04:09, 1.84 it/s, Epoch 8/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.943000</td>\n",
       "      <td>1.208726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.002600</td>\n",
       "      <td>1.112778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.457000</td>\n",
       "      <td>1.119361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.872600</td>\n",
       "      <td>1.141682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.465300</td>\n",
       "      <td>1.090458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.443000</td>\n",
       "      <td>1.099380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.132500</td>\n",
       "      <td>1.121802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.017500</td>\n",
       "      <td>1.120751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0905, epochs=8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▃▄▁▂▃▃</td></tr><tr><td>eval/runtime</td><td>▄▁▄▃█▇▃▅</td></tr><tr><td>eval/samples_per_second</td><td>▅█▅▆▁▂▆▄</td></tr><tr><td>eval/steps_per_second</td><td>▅█▅▆▁▂▆▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▂▃▃▄▂▃▃▄▃▂▄▃▃▆▂▄▃▃▄▄▂▇▃▃▁▂▂▃▃▂▄▃▂▄▃</td></tr><tr><td>train/learning_rate</td><td>▁▄████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.12075</td></tr><tr><td>eval/runtime</td><td>1.7767</td></tr><tr><td>eval/samples_per_second</td><td>410.863</td></tr><tr><td>eval/steps_per_second</td><td>51.78</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>736</td></tr><tr><td>train/grad_norm</td><td>29.51261</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>2.0175</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr2e-05_warmup0.05</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/bbakm04i' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/bbakm04i</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_024214-bbakm04i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 3/6: lr=1e-05, warmup=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_024903-6k9c1cpe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/6k9c1cpe' target=\"_blank\">sweep_lr1e-05_warmup0.1</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/6k9c1cpe' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/6k9c1cpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409d81fa11f142a5a1301c4a4a9c073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 828/1196 07:25 < 03:18, 1.85 it/s, Epoch 9/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.552400</td>\n",
       "      <td>1.372548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.574600</td>\n",
       "      <td>1.119838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.014200</td>\n",
       "      <td>1.091149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.378100</td>\n",
       "      <td>1.099610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.934500</td>\n",
       "      <td>1.045433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.016200</td>\n",
       "      <td>1.028601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.717200</td>\n",
       "      <td>1.060705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.602100</td>\n",
       "      <td>1.069274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.484400</td>\n",
       "      <td>1.052855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0286, epochs=9\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▂▂▁▁▂▂▁</td></tr><tr><td>eval/runtime</td><td>▂▁▁▂▃▅█▃█</td></tr><tr><td>eval/samples_per_second</td><td>▇██▇▆▄▁▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▇██▇▆▄▁▆▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆█▁▁▂▂▃▃▃▃▂▄▃▃▅▂▃▄▃▄▂▃▇▄▄▁▂▃▃▂▄▄▄▃▅▂▃▃▃▃</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▅▇█████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃</td></tr><tr><td>train/loss</td><td>█▇▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.05285</td></tr><tr><td>eval/runtime</td><td>1.8194</td></tr><tr><td>eval/samples_per_second</td><td>401.225</td></tr><tr><td>eval/steps_per_second</td><td>50.565</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>828</td></tr><tr><td>train/grad_norm</td><td>31.92347</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.4844</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr1e-05_warmup0.1</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/6k9c1cpe' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/6k9c1cpe</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_024903-6k9c1cpe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 4/6: lr=1e-05, warmup=0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_025637-8u5khy6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/8u5khy6y' target=\"_blank\">sweep_lr1e-05_warmup0.05</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/8u5khy6y' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/8u5khy6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f446446fba644979fbebe133d3bdd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 828/1196 07:27 < 03:19, 1.85 it/s, Epoch 9/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.569900</td>\n",
       "      <td>1.249349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.355600</td>\n",
       "      <td>1.099825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.874400</td>\n",
       "      <td>1.084962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.317900</td>\n",
       "      <td>1.103624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.907200</td>\n",
       "      <td>1.050397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.989300</td>\n",
       "      <td>1.028154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.708700</td>\n",
       "      <td>1.070450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.602300</td>\n",
       "      <td>1.081128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.498100</td>\n",
       "      <td>1.059621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0282, epochs=9\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▃▃▂▁▂▃▂</td></tr><tr><td>eval/runtime</td><td>▇█▄▂▁▁▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▂▁▅▇██▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▂▁▅▇██▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▁▂▁▂▁▃▃▃▂▂▄▃▂▅▁▄▄▃▄▂▃█▄▄▁▂▃▃▂▄▃▄▃▅▂▂▃▃▃</td></tr><tr><td>train/learning_rate</td><td>▁▄████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂</td></tr><tr><td>train/loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.05962</td></tr><tr><td>eval/runtime</td><td>1.7814</td></tr><tr><td>eval/samples_per_second</td><td>409.788</td></tr><tr><td>eval/steps_per_second</td><td>51.644</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>828</td></tr><tr><td>train/grad_norm</td><td>31.84941</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.4981</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr1e-05_warmup0.05</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/8u5khy6y' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/8u5khy6y</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_025637-8u5khy6y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 5/6: lr=5e-06, warmup=0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_030412-twumgcc6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/twumgcc6' target=\"_blank\">sweep_lr5e-06_warmup0.1</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/twumgcc6' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/twumgcc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaab87003ea4d33ac09db70291ec5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 828/1196 07:26 < 03:19, 1.85 it/s, Epoch 9/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.679200</td>\n",
       "      <td>1.636586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.141000</td>\n",
       "      <td>1.190920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.613900</td>\n",
       "      <td>1.090894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.963600</td>\n",
       "      <td>1.065102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.465800</td>\n",
       "      <td>1.069295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.638300</td>\n",
       "      <td>1.023155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.331100</td>\n",
       "      <td>1.053011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.186600</td>\n",
       "      <td>1.070229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.134300</td>\n",
       "      <td>1.035873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0232, epochs=9\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▂▁▂▁▁▂▁</td></tr><tr><td>eval/runtime</td><td>▄▅▆▅▄█▁▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▅▃▃▄▅▁██▅</td></tr><tr><td>eval/steps_per_second</td><td>▅▄▃▄▅▁██▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄▇▅▂▂▁▃▂▂▂▂▃▃▂▄▂▄▄▃▃▂▄█▄▄▂▃▃▄▂▅▃▄▄▅▃▃▃▄▃</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▅▇█████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃</td></tr><tr><td>train/loss</td><td>█▇▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.03587</td></tr><tr><td>eval/runtime</td><td>1.7731</td></tr><tr><td>eval/samples_per_second</td><td>411.7</td></tr><tr><td>eval/steps_per_second</td><td>51.886</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>828</td></tr><tr><td>train/grad_norm</td><td>36.3521</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.1343</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr5e-06_warmup0.1</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/twumgcc6' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/twumgcc6</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_030412-twumgcc6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPU memory before run: 0.47 GB allocated\n",
      "RUN 6/6: lr=5e-06, warmup=0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/developer/project/wandb/run-20260127_031150-sd4wymkq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/sd4wymkq' target=\"_blank\">sweep_lr5e-06_warmup0.05</a></strong> to <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/sd4wymkq' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/sd4wymkq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a01c178e1d4c2984a1b5a5188aaf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 828/1196 07:26 < 03:19, 1.85 it/s, Epoch 9/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.579000</td>\n",
       "      <td>1.407976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.926600</td>\n",
       "      <td>1.153861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.495800</td>\n",
       "      <td>1.082108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.918000</td>\n",
       "      <td>1.061034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.443500</td>\n",
       "      <td>1.067770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.624900</td>\n",
       "      <td>1.023084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.330300</td>\n",
       "      <td>1.052614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.192100</td>\n",
       "      <td>1.071335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>1.038861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: val_loss=1.0231, epochs=9\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▂▂▂▁▂▂▁</td></tr><tr><td>eval/runtime</td><td>▃▃▂▃▂▁▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▇▆▇█▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▇▆▇█▇█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▅▇▁▁▂▁▃▃▃▂▂▃▃▂▄▂▃▄▃▄▂▄█▄▄▂▃▃▄▂▅▃▄▄▅▃▃▃▄▃</td></tr><tr><td>train/learning_rate</td><td>▁▄████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.03886</td></tr><tr><td>eval/runtime</td><td>1.7851</td></tr><tr><td>eval/samples_per_second</td><td>408.94</td></tr><tr><td>eval/steps_per_second</td><td>51.538</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>828</td></tr><tr><td>train/grad_norm</td><td>36.17868</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.1423</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweep_lr5e-06_warmup0.05</strong> at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/sd4wymkq' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep/runs/sd4wymkq</a><br> View project at: <a href='https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep' target=\"_blank\">https://wandb.ai/scaranoalex-university-of-trento/talent-matching-sweep</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260127_031150-sd4wymkq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sweep complete\n"
     ]
    }
   ],
   "source": [
    "# run hyperparameter sweep with proper memory management\n",
    "sweep_results = []\n",
    "run_num = 1\n",
    "\n",
    "# cleanup: free memory from initial training (Sections 4-8) before starting sweep\n",
    "try:\n",
    "    del model, trainer, loss, base_loss\n",
    "    print(\"Cleaned up initial training objects\")\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for lr in LEARNING_RATES:\n",
    "    for warmup in WARMUP_RATIOS:\n",
    "        # cleanup before each run\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Log memory status\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"GPU memory before run: {allocated:.2f} GB allocated\")\n",
    "        \n",
    "        run_name = f\"sweep_lr{lr}_warmup{warmup}\"\n",
    "        output_dir = f\"output/models/sweep/{run_name}\"\n",
    "        \n",
    "        print(f\"RUN {run_num}/{total_runs}: lr={lr}, warmup={warmup}\")\n",
    "        \n",
    "        # init wandb for this run\n",
    "        wandb.init(\n",
    "            project=\"talent-matching-sweep\",\n",
    "            name=run_name,\n",
    "            config={\"learning_rate\": lr, \"warmup_ratio\": warmup, \"epochs\": SWEEP_EPOCHS},\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # load fresh model\n",
    "        sweep_model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "        sweep_base_loss = MultipleNegativesRankingLoss(sweep_model)\n",
    "        sweep_loss = MatryoshkaLoss(\n",
    "            model=sweep_model,\n",
    "            loss=sweep_base_loss,\n",
    "            matryoshka_dims=[768, 512, 256, 128, 64]\n",
    "        )\n",
    "        \n",
    "        # training args for this run\n",
    "        sweep_args = SentenceTransformerTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=SWEEP_EPOCHS,\n",
    "            per_device_train_batch_size=64,\n",
    "            learning_rate=lr,\n",
    "            warmup_ratio=warmup,\n",
    "            fp16=True,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            greater_is_better=False,\n",
    "            logging_steps=20,\n",
    "            report_to=\"wandb\",\n",
    "        )\n",
    "        \n",
    "        # early stopping\n",
    "        sweep_early_stop = EarlyStoppingCallback(\n",
    "            early_stopping_patience=SWEEP_PATIENCE,\n",
    "            early_stopping_threshold=0.001\n",
    "        )\n",
    "        \n",
    "        # trainer\n",
    "        sweep_trainer = SentenceTransformerTrainer(\n",
    "            model=sweep_model,\n",
    "            args=sweep_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            loss=sweep_loss,\n",
    "            callbacks=[sweep_early_stop]\n",
    "        )\n",
    "        \n",
    "        # train\n",
    "        sweep_trainer.train()\n",
    "        \n",
    "        # save result\n",
    "        final_loss = sweep_trainer.state.best_metric\n",
    "        epochs_done = sweep_trainer.state.epoch\n",
    "        sweep_results.append({\n",
    "            \"run\": run_name,\n",
    "            \"lr\": lr,\n",
    "            \"warmup\": warmup,\n",
    "            \"val_loss\": final_loss,\n",
    "            \"epochs\": epochs_done\n",
    "        })\n",
    "        \n",
    "        print(f\"Result: val_loss={final_loss:.4f}, epochs={epochs_done:.0f}\")\n",
    "        \n",
    "        # save model\n",
    "        sweep_model.save(output_dir)\n",
    "        \n",
    "        # finish wandb run\n",
    "        wandb.finish()\n",
    "        \n",
    "        # aggressive cleanup after each run\n",
    "        # must delete in correct order: trainer first (holds references), then model\n",
    "        del sweep_trainer\n",
    "        del sweep_loss, sweep_base_loss\n",
    "        del sweep_model\n",
    "        \n",
    "        # force Python garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        run_num += 1\n",
    "\n",
    "print(\"\\nSweep complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "r9591s6srwg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWEEP RESULTS (sorted by validation loss):\n",
      "                     run       lr  warmup  val_loss  epochs\n",
      "sweep_lr5e-06_warmup0.05 0.000005    0.05  1.023084     9.0\n",
      " sweep_lr5e-06_warmup0.1 0.000005    0.10  1.023155     9.0\n",
      "sweep_lr1e-05_warmup0.05 0.000010    0.05  1.028154     9.0\n",
      " sweep_lr1e-05_warmup0.1 0.000010    0.10  1.028601     9.0\n",
      " sweep_lr2e-05_warmup0.1 0.000020    0.10  1.088344     8.0\n",
      "sweep_lr2e-05_warmup0.05 0.000020    0.05  1.090458     8.0\n",
      "\n",
      "BEST MODEL:\n",
      "  learning rate: 5e-06\n",
      "  warmup ratio: 0.05\n",
      "  validation loss: 1.0231\n",
      "  epochs trained: 9\n"
     ]
    }
   ],
   "source": [
    "# compare sweep results\n",
    "results_df = pd.DataFrame(sweep_results)\n",
    "results_df = results_df.sort_values(\"val_loss\")\n",
    "\n",
    "print(\"SWEEP RESULTS (sorted by validation loss):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# best model\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nBEST MODEL:\")\n",
    "print(f\"  learning rate: {best['lr']}\")\n",
    "print(f\"  warmup ratio: {best['warmup']}\")\n",
    "print(f\"  validation loss: {best['val_loss']:.4f}\")\n",
    "print(f\"  epochs trained: {best['epochs']:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hshciit0m4m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model copied to: output/models/cv-job-matcher-e5-best\n",
      "Results saved to: output/models/sweep/sweep_results.csv\n"
     ]
    }
   ],
   "source": [
    "# copy best model to main location\n",
    "import shutil\n",
    "\n",
    "best_src = f\"output/models/sweep/{best['run']}\"\n",
    "best_dst = os.path.join(PROJECT_ROOT, \"training\", \"output\", \"models\", \"cv-job-matcher-e5-best\")\n",
    "\n",
    "if os.path.exists(best_dst):\n",
    "    shutil.rmtree(best_dst)\n",
    "shutil.copytree(best_src, best_dst)\n",
    "\n",
    "print(f\"Best model copied to: {best_dst}\")\n",
    "\n",
    "# save sweep results\n",
    "os.makedirs(\"output/models/sweep\", exist_ok=True)\n",
    "results_df.to_csv(\"output/models/sweep/sweep_results.csv\", index=False)\n",
    "print(f\"Results saved to: output/models/sweep/sweep_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talent-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
